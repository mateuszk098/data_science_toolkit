{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ![Keras](https://img.shields.io/badge/Keras-%23D00000.svg?style=for-the-badge&logo=Keras&logoColor=white) **TRAINING DEEP NEURAL NETWORKS - EXERCISES**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **SETUP:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../initial_settings.py\n",
    "\"\"\"\n",
    "Initial settings for data analysis and machine learning.\n",
    "Use this with: %load ../initial_settings.py\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from packaging import version\n",
    "\n",
    "# This notebook requires Python 3.7 or above and Scikit-Learn 1.0.1 or above.\n",
    "assert sys.version_info >= (3, 7)\n",
    "assert version.parse(sklearn.__version__) >= version.parse(\"1.0.1\")\n",
    "\n",
    "# And TensorFlow 2.8 or above.\n",
    "assert version.parse(tf.__version__) >= version.parse(\"2.8.0\")\n",
    "\n",
    "# Graphviz source.\n",
    "os.environ[\"PATH\"] += os.pathsep + \"C:/Programy/Graphviz/bin/\"\n",
    "\n",
    "# Default settings for matplotlib.\n",
    "DARK_BLUE = \"#03002e\"\n",
    "LIGHT_GRAY = \"#8f8f99\"\n",
    "\n",
    "plt.rc(\"font\", size=14)\n",
    "plt.rc(\"legend\", fontsize=14)\n",
    "plt.rc(\"text\", color=DARK_BLUE)\n",
    "\n",
    "plt.rc(\"axes\", labelsize=14)\n",
    "plt.rc(\"axes\", titlesize=14)\n",
    "plt.rc(\"axes\", labelpad=10)\n",
    "plt.rc(\"axes\", labelcolor=DARK_BLUE)\n",
    "plt.rc(\"axes\", grid=True)\n",
    "\n",
    "plt.rc(\"xtick\", labelsize=12, color=DARK_BLUE)\n",
    "plt.rc(\"ytick\", labelsize=12, color=DARK_BLUE)\n",
    "plt.rc(\"xtick.major\", pad=10)\n",
    "plt.rc(\"ytick.major\", pad=10)\n",
    "\n",
    "plt.rc(\"grid\", color=LIGHT_GRAY)\n",
    "plt.rc(\"grid\", linestyle=\"dashed\")\n",
    "plt.rc(\"grid\", linewidth=0.5)\n",
    "plt.rc(\"grid\", alpha=0.5)\n",
    "\n",
    "# Create a directory for matplotlib images.\n",
    "IMAGES_PATH = Path(\"images\")\n",
    "IMAGES_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def save_fig(\n",
    "    fig_id, tight_layout=True, fig_extension=\"png\", resolution=300, facecolor=\"w\"\n",
    "):\n",
    "    path = IMAGES_PATH / f\"{fig_id}.{fig_extension}\"\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution, facecolor=facecolor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **EXERCISE 01:**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a.\n",
    "*Exercise: Build a DNN with 20 hidden layers of 100 neurons each (that's too many, but it's the point of this exercise). Use He initialization and the Swish activation function.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(\n",
    "        tf.keras.layers.Dense(100, activation=\"swish\", kernel_initializer=\"he_normal\")\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b.\n",
    "*Exercise: Using Nadam optimization and early stopping, train the network on the CIFAR10 dataset. You can load it with `tf.keras.datasets.cifar10.load_data()`. The dataset is composed of 60,000 32 × 32–pixel color images (50,000 for training, 10,000 for testing) with 10 classes, so you'll need a softmax output layer with 10 neurons. Remember to search for the right learning rate each time you change the model's architecture or hyperparameters.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use a Nadam optimizer with a learning rate of 5e-5. I tried learning rates 1e-5, 3e-5, 1e-4, 3e-4, 1e-3, 3e-3 and 1e-2, and I compared their learning curves for 10 epochs each (using the TensorBoard callback, below). The learning rates 3e-5 and 1e-4 were pretty good, so I tried 5e-5, which turned out to be slightly better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=5e-5)\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=\"accuracy\"\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the CIFAR10 dataset. We also want to use early stopping, so we need a validation set. Let's use the first 5,000 images of the original training set as the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10 = tf.keras.datasets.cifar10.load_data()\n",
    "(X_train_full, y_train_full), (X_test, y_test) = cifar10\n",
    "\n",
    "X_train = X_train_full[5000:]\n",
    "y_train = y_train_full[5000:]\n",
    "X_valid = X_train_full[:5000]\n",
    "y_valid = y_train_full[:5000]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create the callbacks we need and train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=20, restore_best_weights=True\n",
    ")\n",
    "model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"models/my_cifar10_model\", save_best_only=True\n",
    ")\n",
    "\n",
    "run_index = 1  # Increment every time you train the model.\n",
    "run_logdir = Path() / \"logs\" / \"my_cifar10_logs\" / f\"run_{run_index:03d}\"\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1403/1407 [============================>.] - ETA: 0s - loss: 8.2468 - accuracy: 0.1648"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 21s 11ms/step - loss: 8.2326 - accuracy: 0.1650 - val_loss: 2.1847 - val_accuracy: 0.2196\n",
      "Epoch 2/100\n",
      "1404/1407 [============================>.] - ETA: 0s - loss: 2.1044 - accuracy: 0.2326"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 14s 10ms/step - loss: 2.1042 - accuracy: 0.2326 - val_loss: 2.0371 - val_accuracy: 0.2348\n",
      "Epoch 3/100\n",
      "1405/1407 [============================>.] - ETA: 0s - loss: 1.9919 - accuracy: 0.2687"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.9918 - accuracy: 0.2687 - val_loss: 1.9821 - val_accuracy: 0.2730\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 1.9185 - accuracy: 0.2984"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.9185 - accuracy: 0.2984 - val_loss: 1.9720 - val_accuracy: 0.3036\n",
      "Epoch 5/100\n",
      "1405/1407 [============================>.] - ETA: 0s - loss: 1.8572 - accuracy: 0.3276"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.8572 - accuracy: 0.3276 - val_loss: 1.8670 - val_accuracy: 0.3246\n",
      "Epoch 6/100\n",
      "1406/1407 [============================>.] - ETA: 0s - loss: 1.8046 - accuracy: 0.3478"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.8045 - accuracy: 0.3478 - val_loss: 1.8037 - val_accuracy: 0.3528\n",
      "Epoch 7/100\n",
      "1405/1407 [============================>.] - ETA: 0s - loss: 1.7632 - accuracy: 0.3640"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.7632 - accuracy: 0.3640 - val_loss: 1.7681 - val_accuracy: 0.3582\n",
      "Epoch 8/100\n",
      "1405/1407 [============================>.] - ETA: 0s - loss: 1.7206 - accuracy: 0.3803"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.7206 - accuracy: 0.3803 - val_loss: 1.6953 - val_accuracy: 0.3836\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.6809 - accuracy: 0.3978 - val_loss: 1.7087 - val_accuracy: 0.3918\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.6529 - accuracy: 0.4063 - val_loss: 1.7243 - val_accuracy: 0.3772\n",
      "Epoch 11/100\n",
      "1401/1407 [============================>.] - ETA: 0s - loss: 1.6250 - accuracy: 0.4185"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.6251 - accuracy: 0.4183 - val_loss: 1.6687 - val_accuracy: 0.3968\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 1.6013 - accuracy: 0.4264"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.6013 - accuracy: 0.4264 - val_loss: 1.6626 - val_accuracy: 0.4068\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 1.5785 - accuracy: 0.4347"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.5785 - accuracy: 0.4347 - val_loss: 1.6041 - val_accuracy: 0.4274\n",
      "Epoch 14/100\n",
      "1403/1407 [============================>.] - ETA: 0s - loss: 1.5618 - accuracy: 0.4395"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.5614 - accuracy: 0.4396 - val_loss: 1.5995 - val_accuracy: 0.4124\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.5411 - accuracy: 0.4454 - val_loss: 1.6040 - val_accuracy: 0.4180\n",
      "Epoch 16/100\n",
      "1404/1407 [============================>.] - ETA: 0s - loss: 1.5248 - accuracy: 0.4523"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.5245 - accuracy: 0.4524 - val_loss: 1.5710 - val_accuracy: 0.4376\n",
      "Epoch 17/100\n",
      "1406/1407 [============================>.] - ETA: 0s - loss: 1.5106 - accuracy: 0.4563"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.5106 - accuracy: 0.4563 - val_loss: 1.5654 - val_accuracy: 0.4376\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.4939 - accuracy: 0.4638 - val_loss: 1.6029 - val_accuracy: 0.4246\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.4847 - accuracy: 0.4680 - val_loss: 1.5788 - val_accuracy: 0.4292\n",
      "Epoch 20/100\n",
      "1401/1407 [============================>.] - ETA: 0s - loss: 1.4730 - accuracy: 0.4699"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.4737 - accuracy: 0.4694 - val_loss: 1.5558 - val_accuracy: 0.4428\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.4601 - accuracy: 0.4767 - val_loss: 1.5714 - val_accuracy: 0.4448\n",
      "Epoch 22/100\n",
      "1403/1407 [============================>.] - ETA: 0s - loss: 1.4459 - accuracy: 0.4816"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.4464 - accuracy: 0.4814 - val_loss: 1.5323 - val_accuracy: 0.4534\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.4341 - accuracy: 0.4850 - val_loss: 1.5471 - val_accuracy: 0.4418\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.4238 - accuracy: 0.4890 - val_loss: 1.5846 - val_accuracy: 0.4298\n",
      "Epoch 25/100\n",
      "1400/1407 [============================>.] - ETA: 0s - loss: 1.4135 - accuracy: 0.4916"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.4139 - accuracy: 0.4913 - val_loss: 1.5269 - val_accuracy: 0.4600\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.4037 - accuracy: 0.4965 - val_loss: 1.5596 - val_accuracy: 0.4400\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 1.3941 - accuracy: 0.5028"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.3941 - accuracy: 0.5028 - val_loss: 1.5223 - val_accuracy: 0.4650\n",
      "Epoch 28/100\n",
      "1402/1407 [============================>.] - ETA: 0s - loss: 1.3868 - accuracy: 0.5012"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.3873 - accuracy: 0.5010 - val_loss: 1.5065 - val_accuracy: 0.4616\n",
      "Epoch 29/100\n",
      "1402/1407 [============================>.] - ETA: 0s - loss: 1.3771 - accuracy: 0.5045"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.3773 - accuracy: 0.5046 - val_loss: 1.5031 - val_accuracy: 0.4630\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.3669 - accuracy: 0.5075 - val_loss: 1.5834 - val_accuracy: 0.4428\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3604 - accuracy: 0.5109 - val_loss: 1.5609 - val_accuracy: 0.4510\n",
      "Epoch 32/100\n",
      "1400/1407 [============================>.] - ETA: 0s - loss: 1.3501 - accuracy: 0.5149"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.3502 - accuracy: 0.5149 - val_loss: 1.4931 - val_accuracy: 0.4736\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.3428 - accuracy: 0.5166 - val_loss: 1.5613 - val_accuracy: 0.4624\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.3334 - accuracy: 0.5225 - val_loss: 1.5003 - val_accuracy: 0.4824\n",
      "Epoch 35/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3248 - accuracy: 0.5246 - val_loss: 1.5255 - val_accuracy: 0.4608\n",
      "Epoch 36/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.3199 - accuracy: 0.5262 - val_loss: 1.5158 - val_accuracy: 0.4660\n",
      "Epoch 37/100\n",
      "1403/1407 [============================>.] - ETA: 0s - loss: 1.3103 - accuracy: 0.5287"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.3097 - accuracy: 0.5290 - val_loss: 1.4928 - val_accuracy: 0.4714\n",
      "Epoch 38/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.3028 - accuracy: 0.5330 - val_loss: 1.5304 - val_accuracy: 0.4618\n",
      "Epoch 39/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.2963 - accuracy: 0.5343 - val_loss: 1.5183 - val_accuracy: 0.4660\n",
      "Epoch 40/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.2863 - accuracy: 0.5378 - val_loss: 1.5246 - val_accuracy: 0.4660\n",
      "Epoch 41/100\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.2805 - accuracy: 0.5415 - val_loss: 1.4993 - val_accuracy: 0.4770\n",
      "Epoch 42/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.2761 - accuracy: 0.5437 - val_loss: 1.5126 - val_accuracy: 0.4712\n",
      "Epoch 43/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.2679 - accuracy: 0.5456 - val_loss: 1.4982 - val_accuracy: 0.4750\n",
      "Epoch 44/100\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.2580 - accuracy: 0.5480 - val_loss: 1.5208 - val_accuracy: 0.4766\n",
      "Epoch 45/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.2542 - accuracy: 0.5528 - val_loss: 1.5122 - val_accuracy: 0.4712\n",
      "Epoch 46/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.2463 - accuracy: 0.5538 - val_loss: 1.5091 - val_accuracy: 0.4718\n",
      "Epoch 47/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.2426 - accuracy: 0.5549 - val_loss: 1.5008 - val_accuracy: 0.4814\n",
      "Epoch 48/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.2338 - accuracy: 0.5584 - val_loss: 1.4980 - val_accuracy: 0.4800\n",
      "Epoch 49/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.2229 - accuracy: 0.5608 - val_loss: 1.5201 - val_accuracy: 0.4738\n",
      "Epoch 50/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.2201 - accuracy: 0.5627 - val_loss: 1.5179 - val_accuracy: 0.4788\n",
      "Epoch 51/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.2131 - accuracy: 0.5648 - val_loss: 1.5204 - val_accuracy: 0.4740\n",
      "Epoch 52/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.2070 - accuracy: 0.5674 - val_loss: 1.5260 - val_accuracy: 0.4744\n",
      "Epoch 53/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.2001 - accuracy: 0.5696 - val_loss: 1.5176 - val_accuracy: 0.4774\n",
      "Epoch 54/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.1949 - accuracy: 0.5722 - val_loss: 1.5653 - val_accuracy: 0.4564\n",
      "Epoch 55/100\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.1892 - accuracy: 0.5745 - val_loss: 1.5330 - val_accuracy: 0.4704\n",
      "Epoch 56/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.1848 - accuracy: 0.5752 - val_loss: 1.5528 - val_accuracy: 0.4680\n",
      "Epoch 57/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.1770 - accuracy: 0.5769 - val_loss: 1.5306 - val_accuracy: 0.4844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23917e7b640>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=callbacks,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 3ms/step - loss: 1.4928 - accuracy: 0.4714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.492821455001831, 0.4713999927043915]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c.\n",
    "*Exercise: Now try adding Batch Normalization and compare the learning curves: Is it converging faster than before? Does it produce a better model? How does it affect training speed?*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below is very similar to the code above, with a few changes:\n",
    "\n",
    "* I added a BN layer after every Dense layer (before the activation function), except for the output layer.\n",
    "* I changed the learning rate to 5e-4. I experimented with 1e-5, 3e-5, 5e-5, 1e-4, 3e-4, 5e-4, 1e-3 and 3e-3, and I chose the one with the best validation performance after 20 epochs.\n",
    "* I renamed the run directories to run_bn_* and the model file name to `my_cifar10_bn_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 30s 12ms/step - loss: 2.0266 - accuracy: 0.2574 - val_loss: 1.8578 - val_accuracy: 0.3172\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.7822 - accuracy: 0.3540 - val_loss: 1.7983 - val_accuracy: 0.3418\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.6770 - accuracy: 0.3994 - val_loss: 1.6869 - val_accuracy: 0.3806\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.6102 - accuracy: 0.4274 - val_loss: 1.8078 - val_accuracy: 0.3678\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.5516 - accuracy: 0.4471 - val_loss: 1.6601 - val_accuracy: 0.4040\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.5025 - accuracy: 0.4670 - val_loss: 1.6769 - val_accuracy: 0.4116\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.4543 - accuracy: 0.4847 - val_loss: 1.6730 - val_accuracy: 0.4058\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.4175 - accuracy: 0.4978 - val_loss: 1.6631 - val_accuracy: 0.4148\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.3853 - accuracy: 0.5115 - val_loss: 1.5378 - val_accuracy: 0.4454\n",
      "Epoch 10/100\n",
      "1404/1407 [============================>.] - ETA: 0s - loss: 1.3513 - accuracy: 0.5224"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 25s 18ms/step - loss: 1.3512 - accuracy: 0.5224 - val_loss: 1.4487 - val_accuracy: 0.4882\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.3275 - accuracy: 0.5318 - val_loss: 1.5097 - val_accuracy: 0.4700\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2929 - accuracy: 0.5455 - val_loss: 1.8836 - val_accuracy: 0.3676\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2697 - accuracy: 0.5496 - val_loss: 1.5125 - val_accuracy: 0.4634\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.2475 - accuracy: 0.5580 - val_loss: 1.4663 - val_accuracy: 0.4858\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2210 - accuracy: 0.5696 - val_loss: 1.7082 - val_accuracy: 0.4460\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2049 - accuracy: 0.5742 - val_loss: 1.5319 - val_accuracy: 0.4612\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.1867 - accuracy: 0.5799 - val_loss: 1.4898 - val_accuracy: 0.4932\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.1668 - accuracy: 0.5908 - val_loss: 1.6454 - val_accuracy: 0.4394\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.1509 - accuracy: 0.5928 - val_loss: 1.5659 - val_accuracy: 0.4818\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.1314 - accuracy: 0.6020 - val_loss: 1.5056 - val_accuracy: 0.4952\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.1172 - accuracy: 0.6041 - val_loss: 1.5241 - val_accuracy: 0.4840\n",
      "Epoch 22/100\n",
      "1404/1407 [============================>.] - ETA: 0s - loss: 1.0971 - accuracy: 0.6118"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 28s 20ms/step - loss: 1.0975 - accuracy: 0.6117 - val_loss: 1.4301 - val_accuracy: 0.5130\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.0872 - accuracy: 0.6184 - val_loss: 1.5822 - val_accuracy: 0.4656\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.0678 - accuracy: 0.6249 - val_loss: 1.4755 - val_accuracy: 0.5048\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.0584 - accuracy: 0.6246 - val_loss: 1.6803 - val_accuracy: 0.4568\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.0409 - accuracy: 0.6288 - val_loss: 1.4512 - val_accuracy: 0.5060\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.0297 - accuracy: 0.6377 - val_loss: 1.5097 - val_accuracy: 0.4988\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.0230 - accuracy: 0.6408 - val_loss: 1.9051 - val_accuracy: 0.4296\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.0088 - accuracy: 0.6439 - val_loss: 1.5829 - val_accuracy: 0.4890\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.9988 - accuracy: 0.6480 - val_loss: 1.6224 - val_accuracy: 0.4726\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 0.9862 - accuracy: 0.6513 - val_loss: 1.4508 - val_accuracy: 0.5162\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.9746 - accuracy: 0.6544 - val_loss: 1.7721 - val_accuracy: 0.4446\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.9602 - accuracy: 0.6616 - val_loss: 1.5864 - val_accuracy: 0.4984\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 0.9536 - accuracy: 0.6634 - val_loss: 1.5673 - val_accuracy: 0.4896\n",
      "Epoch 35/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 0.9473 - accuracy: 0.6666 - val_loss: 1.5753 - val_accuracy: 0.4792\n",
      "Epoch 36/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 0.9345 - accuracy: 0.6706 - val_loss: 1.5344 - val_accuracy: 0.5064\n",
      "Epoch 37/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 0.9196 - accuracy: 0.6741 - val_loss: 1.5647 - val_accuracy: 0.4992\n",
      "Epoch 38/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 0.9171 - accuracy: 0.6746 - val_loss: 1.5664 - val_accuracy: 0.4892\n",
      "Epoch 39/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 0.9019 - accuracy: 0.6825 - val_loss: 1.6398 - val_accuracy: 0.4868\n",
      "Epoch 40/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 0.8924 - accuracy: 0.6850 - val_loss: 1.5915 - val_accuracy: 0.4956\n",
      "Epoch 41/100\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 0.8865 - accuracy: 0.6879 - val_loss: 1.5594 - val_accuracy: 0.4966\n",
      "Epoch 42/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 0.8752 - accuracy: 0.6895 - val_loss: 1.6878 - val_accuracy: 0.4914\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.4301 - accuracy: 0.5130\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.430132508277893, 0.5130000114440918]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(tf.keras.layers.Dense(100, kernel_initializer=\"he_normal\"))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Activation(\"swish\"))\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=5e-4)\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=20, restore_best_weights=True\n",
    ")\n",
    "model_check_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"models/my_cifar10_bn_model\", save_best_only=True\n",
    ")\n",
    "\n",
    "run_index = 1  # increment every time you train the model\n",
    "run_logdir = Path() / \"logs\" / \"my_cifar10_logs\" / f\"run_bn_{run_index:03d}\"\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "model.evaluate(X_valid, y_valid)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *Is the model converging faster than before?* Much faster! The previous model took 29 epochs to reach the lowest validation loss, while the new model achieved that same loss in just 12 epochs and continued to make progress until the 17th epoch. The BN layers stabilized training and allowed us to use a much larger learning rate, so convergence was faster.\n",
    "* *Does BN produce a better model?* Yes! The final model is also much better, with 50.7% validation accuracy instead of 46.7%. It's still not a very good model, but at least it's much better than before (a Convolutional Neural Network would do much better, but that's a different topic, see chapter 14).\n",
    "* *How does BN affect training speed?* Although the model converged much faster, each epoch took about 15s instead of 10s, because of the extra computations required by the BN layers. But overall the training time (wall time) to reach the best model was shortened by about 10%."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d.\n",
    "*Exercise: Try replacing Batch Normalization with SELU, and make the necessary adjustements to ensure the network self-normalizes (i.e., standardize the input features, use LeCun normal initialization, make sure the DNN contains only a sequence of dense layers, etc.).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1406/1407 [============================>.] - ETA: 0s - loss: 1.9090 - accuracy: 0.3127"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_selu_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_selu_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 20s 11ms/step - loss: 1.9090 - accuracy: 0.3126 - val_loss: 1.7356 - val_accuracy: 0.3894\n",
      "Epoch 2/100\n",
      "1405/1407 [============================>.] - ETA: 0s - loss: 1.7032 - accuracy: 0.3939"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_selu_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_selu_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.7031 - accuracy: 0.3940 - val_loss: 1.6695 - val_accuracy: 0.3992\n",
      "Epoch 3/100\n",
      "1404/1407 [============================>.] - ETA: 0s - loss: 1.6112 - accuracy: 0.4275"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_selu_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_selu_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.6111 - accuracy: 0.4276 - val_loss: 1.5980 - val_accuracy: 0.4302\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.5439 - accuracy: 0.4537 - val_loss: 1.6371 - val_accuracy: 0.4382\n",
      "Epoch 5/100\n",
      "1401/1407 [============================>.] - ETA: 0s - loss: 1.4938 - accuracy: 0.4742"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_selu_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_selu_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.4939 - accuracy: 0.4742 - val_loss: 1.5563 - val_accuracy: 0.4500\n",
      "Epoch 6/100\n",
      "1406/1407 [============================>.] - ETA: 0s - loss: 1.4457 - accuracy: 0.4921"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_selu_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_selu_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.4458 - accuracy: 0.4921 - val_loss: 1.5544 - val_accuracy: 0.4662\n",
      "Epoch 7/100\n",
      "1406/1407 [============================>.] - ETA: 0s - loss: 1.3989 - accuracy: 0.5102"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_selu_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_selu_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.3989 - accuracy: 0.5102 - val_loss: 1.5478 - val_accuracy: 0.4676\n",
      "Epoch 8/100\n",
      "1403/1407 [============================>.] - ETA: 0s - loss: 1.3583 - accuracy: 0.5257"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_selu_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_selu_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.3581 - accuracy: 0.5257 - val_loss: 1.4862 - val_accuracy: 0.4888\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.3296 - accuracy: 0.5375 - val_loss: 1.5042 - val_accuracy: 0.4722\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2973 - accuracy: 0.5492 - val_loss: 1.5206 - val_accuracy: 0.4848\n",
      "Epoch 11/100\n",
      "1404/1407 [============================>.] - ETA: 0s - loss: 1.2597 - accuracy: 0.5640"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_selu_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_selu_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.2596 - accuracy: 0.5640 - val_loss: 1.4731 - val_accuracy: 0.4928\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2336 - accuracy: 0.5720 - val_loss: 1.5127 - val_accuracy: 0.4898\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.2073 - accuracy: 0.5779 - val_loss: 1.5059 - val_accuracy: 0.4860\n",
      "Epoch 14/100\n",
      "1403/1407 [============================>.] - ETA: 0s - loss: 1.1845 - accuracy: 0.5903"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_selu_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_selu_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.1844 - accuracy: 0.5904 - val_loss: 1.4677 - val_accuracy: 0.4884\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.1569 - accuracy: 0.6008 - val_loss: 1.5412 - val_accuracy: 0.4916\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.1459 - accuracy: 0.6075 - val_loss: 1.5277 - val_accuracy: 0.5048\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.1132 - accuracy: 0.6157 - val_loss: 1.5248 - val_accuracy: 0.5048\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.0907 - accuracy: 0.6248 - val_loss: 1.5363 - val_accuracy: 0.4828\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.0682 - accuracy: 0.6336 - val_loss: 1.5697 - val_accuracy: 0.4924\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.0477 - accuracy: 0.6411 - val_loss: 1.5486 - val_accuracy: 0.4914\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.0302 - accuracy: 0.6462 - val_loss: 1.5858 - val_accuracy: 0.4982\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.0103 - accuracy: 0.6569 - val_loss: 1.6090 - val_accuracy: 0.5012\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.9910 - accuracy: 0.6620 - val_loss: 1.6061 - val_accuracy: 0.5000\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.9764 - accuracy: 0.6690 - val_loss: 1.5511 - val_accuracy: 0.5046\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 0.9587 - accuracy: 0.6758 - val_loss: 1.5822 - val_accuracy: 0.5114\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 925.5479 - accuracy: 0.5180 - val_loss: 1.6431 - val_accuracy: 0.4310\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.2920 - accuracy: 0.5420 - val_loss: 1.5787 - val_accuracy: 0.4566\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2137 - accuracy: 0.5743 - val_loss: 1.5690 - val_accuracy: 0.4682\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.1681 - accuracy: 0.5901 - val_loss: 1.5659 - val_accuracy: 0.4790\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.1300 - accuracy: 0.6040 - val_loss: 1.5673 - val_accuracy: 0.4888\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.0977 - accuracy: 0.6201 - val_loss: 1.5472 - val_accuracy: 0.4928\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.0718 - accuracy: 0.6275 - val_loss: 1.6000 - val_accuracy: 0.4932\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.0524 - accuracy: 0.6351 - val_loss: 1.5713 - val_accuracy: 0.4986\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.0314 - accuracy: 0.6443 - val_loss: 1.5868 - val_accuracy: 0.4974\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.4677 - accuracy: 0.4884\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.467708706855774, 0.48840001225471497]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(\n",
    "        tf.keras.layers.Dense(100, kernel_initializer=\"lecun_normal\", activation=\"selu\")\n",
    "    )\n",
    "\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=7e-4)\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=20, restore_best_weights=True\n",
    ")\n",
    "model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"models/my_cifar10_selu_model\", save_best_only=True\n",
    ")\n",
    "run_index = 1  # increment every time you train the model\n",
    "run_logdir = Path() / \"logs\" / \"my_cifar10_logs\" / f\"run_selu_{run_index:03d}\"\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "\n",
    "X_means = X_train.mean(axis=0)\n",
    "X_stds = X_train.std(axis=0)\n",
    "X_train_scaled = (X_train - X_means) / X_stds\n",
    "X_valid_scaled = (X_valid - X_means) / X_stds\n",
    "X_test_scaled = (X_test - X_means) / X_stds\n",
    "\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(X_valid_scaled, y_valid),\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "model.evaluate(X_valid_scaled, y_valid)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model reached the first model's validation loss in just 8 epochs. After 14 epochs, it reached its lowest validation loss, with about 50.3% accuracy, which is better than the original model (46.7%), but not quite as good as the model using batch normalization (50.7%). Each epoch took only 9 seconds. So it's the fastest model to train so far."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e.\n",
    "*Exercise: Try regularizing the model with alpha dropout. Then, without retraining your model, see if you can achieve better accuracy using MC Dropout.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1405/1407 [============================>.] - ETA: 0s - loss: 1.8892 - accuracy: 0.3246"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_alpha_dropout_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_alpha_dropout_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 27s 15ms/step - loss: 1.8890 - accuracy: 0.3247 - val_loss: 1.7728 - val_accuracy: 0.3700\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 1.6696 - accuracy: 0.4109"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_alpha_dropout_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_alpha_dropout_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.6696 - accuracy: 0.4109 - val_loss: 1.6373 - val_accuracy: 0.4214\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 1.5774 - accuracy: 0.4429"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_alpha_dropout_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_alpha_dropout_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 19s 14ms/step - loss: 1.5774 - accuracy: 0.4429 - val_loss: 1.6071 - val_accuracy: 0.4336\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 1.5157 - accuracy: 0.4679"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_alpha_dropout_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_alpha_dropout_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 19s 14ms/step - loss: 1.5157 - accuracy: 0.4679 - val_loss: 1.5403 - val_accuracy: 0.4576\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.4561 - accuracy: 0.4922 - val_loss: 1.5551 - val_accuracy: 0.4598\n",
      "Epoch 6/100\n",
      "1405/1407 [============================>.] - ETA: 0s - loss: 1.4085 - accuracy: 0.5105"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_alpha_dropout_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\my_cifar10_alpha_dropout_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 19s 14ms/step - loss: 1.4086 - accuracy: 0.5104 - val_loss: 1.4951 - val_accuracy: 0.4790\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.3659 - accuracy: 0.5268 - val_loss: 1.5314 - val_accuracy: 0.4748\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.3206 - accuracy: 0.5406 - val_loss: 1.5053 - val_accuracy: 0.4966\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.2851 - accuracy: 0.5521 - val_loss: 1.5240 - val_accuracy: 0.4750\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2538 - accuracy: 0.5651 - val_loss: 1.5613 - val_accuracy: 0.4880\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.2287 - accuracy: 0.5769 - val_loss: 1.5459 - val_accuracy: 0.5022\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.1928 - accuracy: 0.5894 - val_loss: 1.5084 - val_accuracy: 0.5074\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.1610 - accuracy: 0.6024 - val_loss: 1.5401 - val_accuracy: 0.5106\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.1367 - accuracy: 0.6092 - val_loss: 1.5447 - val_accuracy: 0.5090\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.1062 - accuracy: 0.6207 - val_loss: 1.5826 - val_accuracy: 0.5130\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.0906 - accuracy: 0.6283 - val_loss: 1.6441 - val_accuracy: 0.5214\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.0642 - accuracy: 0.6373 - val_loss: 1.6040 - val_accuracy: 0.5150\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.0444 - accuracy: 0.6441 - val_loss: 1.5994 - val_accuracy: 0.5074\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.0236 - accuracy: 0.6505 - val_loss: 1.6095 - val_accuracy: 0.5126\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.0021 - accuracy: 0.6571 - val_loss: 1.5950 - val_accuracy: 0.5166\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9791 - accuracy: 0.6653 - val_loss: 1.6368 - val_accuracy: 0.5116\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9545 - accuracy: 0.6755 - val_loss: 1.7521 - val_accuracy: 0.5058\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 0.9433 - accuracy: 0.6812 - val_loss: 1.6952 - val_accuracy: 0.5140\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9201 - accuracy: 0.6882 - val_loss: 1.7430 - val_accuracy: 0.5202\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 0.9064 - accuracy: 0.6967 - val_loss: 1.6822 - val_accuracy: 0.5270\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 0.8906 - accuracy: 0.7002 - val_loss: 1.7276 - val_accuracy: 0.5104\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 1.4951 - accuracy: 0.4790\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4950894117355347, 0.4790000021457672]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(\n",
    "        tf.keras.layers.Dense(100, kernel_initializer=\"lecun_normal\", activation=\"selu\")\n",
    "    )\n",
    "model.add(tf.keras.layers.AlphaDropout(rate=0.1))\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=5e-4)\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"]\n",
    ")\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=20, restore_best_weights=True\n",
    ")\n",
    "model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"models/my_cifar10_alpha_dropout_model\", save_best_only=True\n",
    ")\n",
    "\n",
    "run_index = 1\n",
    "run_logdir = Path() / \"logs\" / \"my_cifar10_logs\" / f\"run_alpha_dropout_{run_index:03d}\"\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "\n",
    "X_means = X_train.mean(axis=0)\n",
    "X_stds = X_train.std(axis=0)\n",
    "X_train_scaled = (X_train - X_means) / X_stds\n",
    "X_valid_scaled = (X_valid - X_means) / X_stds\n",
    "X_test_scaled = (X_test - X_means) / X_stds\n",
    "\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(X_valid_scaled, y_valid),\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "model.evaluate(X_valid_scaled, y_valid)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model reaches 48.1% accuracy on the validation set. That's worse than without dropout (50.3%). With an extensive hyperparameter search, it might be possible to do better (I tried dropout rates of 5%, 10%, 20% and 40%, and learning rates 1e-4, 3e-4, 5e-4, and 1e-3), but probably not much better in this case."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use MC Dropout now. We will need the `MCAlphaDropout` class we used earlier, so let's just copy it here for convenience:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCAlphaDropout(tf.keras.layers.AlphaDropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a new model, identical to the one we just trained (with the same weights), but with `MCAlphaDropout` dropout layers instead of `AlphaDropout` layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_model = tf.keras.Sequential(\n",
    "    [\n",
    "        (\n",
    "            MCAlphaDropout(layer.rate)\n",
    "            if isinstance(layer, tf.keras.layers.AlphaDropout)\n",
    "            else layer\n",
    "        )\n",
    "        for layer in model.layers\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let's add a couple utility functions. The first will run the model many times (10 by default) and it will return the mean predicted class probabilities. The second will use these mean probabilities to predict the most likely class for each instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_dropout_predict_probas(mc_model, X, n_samples=10):\n",
    "    Y_probas = [mc_model.predict(X) for sample in range(n_samples)]\n",
    "    return np.mean(Y_probas, axis=0)\n",
    "\n",
    "\n",
    "def mc_dropout_predict_classes(mc_model, X, n_samples=10):\n",
    "    Y_probas = mc_dropout_predict_probas(mc_model, X, n_samples)\n",
    "    return Y_probas.argmax(axis=1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make predictions for all the instances in the validation set, and compute the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 4ms/step\n",
      "157/157 [==============================] - 1s 3ms/step\n",
      "157/157 [==============================] - 0s 3ms/step\n",
      "157/157 [==============================] - 0s 3ms/step\n",
      "157/157 [==============================] - 1s 3ms/step\n",
      "157/157 [==============================] - 0s 3ms/step\n",
      "157/157 [==============================] - 0s 3ms/step\n",
      "157/157 [==============================] - 0s 3ms/step\n",
      "157/157 [==============================] - 0s 3ms/step\n",
      "157/157 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4798"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "y_pred = mc_dropout_predict_classes(mc_model, X_valid_scaled)\n",
    "accuracy = (y_pred == y_valid[:, 0]).mean()\n",
    "accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get back to roughly the accuracy of the model without dropout in this case (about 50.3% accuracy).\n",
    "\n",
    "So the best model we got in this exercise is the Batch Normalization model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f.\n",
    "*Exercise: Retrain your model using 1cycle scheduling and see if it improves training speed and model accuracy.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(\n",
    "        tf.keras.layers.Dense(100, kernel_initializer=\"lecun_normal\", activation=\"selu\")\n",
    "    )\n",
    "\n",
    "model.add(tf.keras.layers.AlphaDropout(rate=0.1))\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD()\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = tf.keras.backend\n",
    "\n",
    "class ExponentialLearningRate(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        self.rates = []\n",
    "        self.losses = []\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.sum_of_epoch_losses = 0\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        mean_epoch_loss = logs[\"loss\"]  # the epoch's mean loss so far \n",
    "        new_sum_of_epoch_losses = mean_epoch_loss * (batch + 1)\n",
    "        batch_loss = new_sum_of_epoch_losses - self.sum_of_epoch_losses\n",
    "        self.sum_of_epoch_losses = new_sum_of_epoch_losses\n",
    "        self.rates.append(K.get_value(self.model.optimizer.learning_rate))\n",
    "        self.losses.append(batch_loss)\n",
    "        K.set_value(self.model.optimizer.learning_rate,\n",
    "                    self.model.optimizer.learning_rate * self.factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def find_learning_rate(model, X, y, epochs=1, batch_size=32, min_rate=1e-4,\n",
    "                       max_rate=1):\n",
    "    init_weights = model.get_weights()\n",
    "    iterations = math.ceil(len(X) / batch_size) * epochs\n",
    "    factor = (max_rate / min_rate) ** (1 / iterations)\n",
    "    init_lr = K.get_value(model.optimizer.learning_rate)\n",
    "    K.set_value(model.optimizer.learning_rate, min_rate)\n",
    "    exp_lr = ExponentialLearningRate(factor)\n",
    "    history = model.fit(X, y, epochs=epochs, batch_size=batch_size,\n",
    "                        callbacks=[exp_lr])\n",
    "    K.set_value(model.optimizer.learning_rate, init_lr)\n",
    "    model.set_weights(init_weights)\n",
    "    return exp_lr.rates, exp_lr.losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lr_vs_loss(rates, losses):\n",
    "    plt.plot(rates, losses, \"b\")\n",
    "    plt.gca().set_xscale('log')\n",
    "    max_loss = losses[0] + min(losses)\n",
    "    plt.hlines(min(losses), min(rates), max(rates), color=\"k\")\n",
    "    plt.axis([min(rates), max(rates), 0, max_loss])\n",
    "    plt.xlabel(\"Learning rate\")\n",
    "    plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneCycleScheduler(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, iterations, max_lr=1e-3, start_lr=None,\n",
    "                 last_iterations=None, last_lr=None):\n",
    "        self.iterations = iterations\n",
    "        self.max_lr = max_lr\n",
    "        self.start_lr = start_lr or max_lr / 10\n",
    "        self.last_iterations = last_iterations or iterations // 10 + 1\n",
    "        self.half_iteration = (iterations - self.last_iterations) // 2\n",
    "        self.last_lr = last_lr or self.start_lr / 1000\n",
    "        self.iteration = 0\n",
    "\n",
    "    def _interpolate(self, iter1, iter2, lr1, lr2):\n",
    "        return (lr2 - lr1) * (self.iteration - iter1) / (iter2 - iter1) + lr1\n",
    "\n",
    "    def on_batch_begin(self, batch, logs):\n",
    "        if self.iteration < self.half_iteration:\n",
    "            lr = self._interpolate(0, self.half_iteration, self.start_lr,\n",
    "                                   self.max_lr)\n",
    "        elif self.iteration < 2 * self.half_iteration:\n",
    "            lr = self._interpolate(self.half_iteration, 2 * self.half_iteration,\n",
    "                                   self.max_lr, self.start_lr)\n",
    "        else:\n",
    "            lr = self._interpolate(2 * self.half_iteration, self.iterations,\n",
    "                                   self.start_lr, self.last_lr)\n",
    "        self.iteration += 1\n",
    "        K.set_value(self.model.optimizer.learning_rate, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352/352 [==============================] - 6s 13ms/step - loss: nan - accuracy: 0.1704\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "rates, losses = find_learning_rate(\n",
    "    model, X_train_scaled, y_train, epochs=1, batch_size=batch_size\n",
    ")\n",
    "plot_lr_vs_loss(rates, losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(\n",
    "        tf.keras.layers.Dense(100, kernel_initializer=\"lecun_normal\", activation=\"selu\")\n",
    "    )\n",
    "\n",
    "model.add(tf.keras.layers.AlphaDropout(rate=0.1))\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=2e-2)\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "352/352 [==============================] - 6s 13ms/step - loss: 2.0450 - accuracy: 0.2844 - val_loss: 1.8288 - val_accuracy: 0.3658\n",
      "Epoch 2/15\n",
      "352/352 [==============================] - 4s 12ms/step - loss: 1.7511 - accuracy: 0.3785 - val_loss: 1.6839 - val_accuracy: 0.4006\n",
      "Epoch 3/15\n",
      "352/352 [==============================] - 5s 13ms/step - loss: 1.6189 - accuracy: 0.4250 - val_loss: 1.6361 - val_accuracy: 0.4186\n",
      "Epoch 4/15\n",
      "352/352 [==============================] - 4s 13ms/step - loss: 1.5495 - accuracy: 0.4497 - val_loss: 1.6044 - val_accuracy: 0.4412\n",
      "Epoch 5/15\n",
      "352/352 [==============================] - 4s 12ms/step - loss: 1.4995 - accuracy: 0.4680 - val_loss: 1.6241 - val_accuracy: 0.4410\n",
      "Epoch 6/15\n",
      "352/352 [==============================] - 4s 12ms/step - loss: 1.4623 - accuracy: 0.4802 - val_loss: 1.5431 - val_accuracy: 0.4520\n",
      "Epoch 7/15\n",
      "352/352 [==============================] - 4s 12ms/step - loss: 1.4271 - accuracy: 0.4928 - val_loss: 1.5923 - val_accuracy: 0.4554\n",
      "Epoch 8/15\n",
      "352/352 [==============================] - 4s 12ms/step - loss: 1.3585 - accuracy: 0.5164 - val_loss: 1.5453 - val_accuracy: 0.4764\n",
      "Epoch 9/15\n",
      "352/352 [==============================] - 4s 12ms/step - loss: 1.2786 - accuracy: 0.5446 - val_loss: 1.5814 - val_accuracy: 0.4674\n",
      "Epoch 10/15\n",
      "352/352 [==============================] - 4s 12ms/step - loss: 1.2124 - accuracy: 0.5661 - val_loss: 1.5387 - val_accuracy: 0.4936\n",
      "Epoch 11/15\n",
      "352/352 [==============================] - 5s 13ms/step - loss: 1.1459 - accuracy: 0.5905 - val_loss: 1.5510 - val_accuracy: 0.4940\n",
      "Epoch 12/15\n",
      "352/352 [==============================] - 4s 13ms/step - loss: 1.0729 - accuracy: 0.6171 - val_loss: 1.5075 - val_accuracy: 0.5028\n",
      "Epoch 13/15\n",
      "352/352 [==============================] - 4s 13ms/step - loss: 1.0053 - accuracy: 0.6409 - val_loss: 1.5425 - val_accuracy: 0.5092\n",
      "Epoch 14/15\n",
      "352/352 [==============================] - 4s 12ms/step - loss: 0.9412 - accuracy: 0.6635 - val_loss: 1.5627 - val_accuracy: 0.5054\n",
      "Epoch 15/15\n",
      "352/352 [==============================] - 4s 12ms/step - loss: 0.8994 - accuracy: 0.6779 - val_loss: 1.5894 - val_accuracy: 0.5094\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 15\n",
    "n_iterations = math.ceil(len(X_train_scaled) / batch_size) * n_epochs\n",
    "onecycle = OneCycleScheduler(n_iterations, max_lr=0.05)\n",
    "history = model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs=n_epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_valid_scaled, y_valid),\n",
    "    callbacks=[onecycle],\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One cycle allowed us to train the model in just 15 epochs, each taking only 2 seconds (thanks to the larger batch size). This is several times faster than the fastest model we trained so far. Moreover, we improved the model's performance (from 50.7% to 52.0%)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
