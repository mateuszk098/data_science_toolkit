{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ![TensorFlow](https://img.shields.io/badge/TensorFlow-%23FF6F00.svg?style=for-the-badge&logo=TensorFlow&logoColor=white) **CHAPTER 12 - CUSTOM MODELS AND TRAINING WITH TENSORFLOW**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **SETUP:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../initial_settings.py\n",
    "\"\"\"\n",
    "Initial settings for data analysis and machine learning.\n",
    "Use this with: %load ../initial_settings.py\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "from packaging import version\n",
    "\n",
    "# This notebook requires Python 3.7 or above and Scikit-Learn 1.0.1 or above.\n",
    "assert sys.version_info >= (3, 7)\n",
    "assert version.parse(sklearn.__version__) >= version.parse(\"1.0.1\")\n",
    "\n",
    "# And TensorFlow 2.8 or above.\n",
    "assert version.parse(tf.__version__) >= version.parse(\"2.8.0\")\n",
    "\n",
    "# Graphviz source.\n",
    "os.environ[\"PATH\"] += os.pathsep + \"C:/Programy/Graphviz/bin/\"\n",
    "\n",
    "# Default settings for matplotlib.\n",
    "DARK_BLUE = \"#03002e\"\n",
    "LIGHT_GRAY = \"#8f8f99\"\n",
    "\n",
    "plt.rc(\"font\", size=14)\n",
    "plt.rc(\"legend\", fontsize=14)\n",
    "plt.rc(\"text\", color=DARK_BLUE)\n",
    "\n",
    "plt.rc(\"axes\", labelsize=14)\n",
    "plt.rc(\"axes\", titlesize=14)\n",
    "plt.rc(\"axes\", labelpad=10)\n",
    "plt.rc(\"axes\", labelcolor=DARK_BLUE)\n",
    "plt.rc(\"axes\", grid=True)\n",
    "\n",
    "plt.rc(\"xtick\", labelsize=12, color=DARK_BLUE)\n",
    "plt.rc(\"ytick\", labelsize=12, color=DARK_BLUE)\n",
    "plt.rc(\"xtick.major\", pad=10)\n",
    "plt.rc(\"ytick.major\", pad=10)\n",
    "\n",
    "plt.rc(\"grid\", color=LIGHT_GRAY)\n",
    "plt.rc(\"grid\", linestyle=\"dashed\")\n",
    "plt.rc(\"grid\", linewidth=0.5)\n",
    "plt.rc(\"grid\", alpha=0.5)\n",
    "\n",
    "# Create a directory for matplotlib images.\n",
    "IMAGES_PATH = Path(\"images\")\n",
    "IMAGES_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def save_fig(\n",
    "    fig_id, tight_layout=True, fig_extension=\"png\", resolution=300, facecolor=\"w\"\n",
    "):\n",
    "    path = IMAGES_PATH / f\"{fig_id}.{fig_extension}\"\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution, facecolor=facecolor)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **USING TENSORFLOW LIKE NUMPY:**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **TENSORS AND OPERATIONS:**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **TENSORS:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.dtype"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **INDEXING:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2., 3.],\n",
       "       [5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[2.],\n",
       "       [5.]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[..., 1, tf.newaxis]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **OPS:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[11., 12., 13.],\n",
       "       [14., 15., 16.]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[14., 32.],\n",
       "       [32., 77.]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t @ tf.transpose(t)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **SCALARS:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=42>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **KERAS LOW-LEVEL API:**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may still run across code that uses Keras's low-level API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[11., 26.],\n",
       "       [14., 35.],\n",
       "       [19., 46.]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = tf.keras.backend\n",
    "K.square(K.transpose(t)) + 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But since Keras does not support multiple backends anymore, you should instead use TF's low-level API directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[11., 26.],\n",
       "       [14., 35.],\n",
       "       [19., 46.]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(tf.transpose(t)) + 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **TENSORS AND NUMPY:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([2., 4., 5.])>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([2., 4., 5.])\n",
    "tf.constant(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([ 4., 16., 25.])>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.square(t)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **TYPE CONVERSIONS:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a int32 tensor [Op:AddV2]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tf.constant(2.0) + tf.constant(40)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a double tensor [Op:AddV2]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tf.constant(2.0) + tf.constant(40., dtype=tf.float64)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=42.0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = tf.constant(40., dtype=tf.float64)\n",
    "tf.constant(2.0) + tf.cast(t2, tf.float32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **VARIABLES:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = tf.Variable([[1., 2., 3.], [4., 5., 6.]])\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2.,  4.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.assign(2 * v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2., 42.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[0, 1].assign(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2., 42.,  0.],\n",
       "       [ 8., 10.,  1.]], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[:, 2].assign([0., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[100.,  42.,   0.],\n",
       "       [  8.,  10., 200.]], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.scatter_nd_update(indices=[[0, 0], [1, 2]], updates=[100., 200.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[4., 5., 6.],\n",
       "       [1., 2., 3.]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – shows how to use scatter_update()\n",
    "sparse_delta = tf.IndexedSlices(values=[[1., 2., 3.], [4., 5., 6.]], indices=[1, 0])\n",
    "v.scatter_update(sparse_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ResourceVariable' object does not support item assignment\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    v[1] = [7., 8., 9.]\n",
    "except TypeError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **STRINGS:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'hello world'>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(b\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'caf\\xc3\\xa9'>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(\"café\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([ 99,  97, 102, 233])>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = tf.constant([ord(c) for c in \"café\"])\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=4>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tf.strings.unicode_encode(u, \"UTF-8\")\n",
    "tf.strings.length(b, unit=\"UTF8_CHAR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([ 99,  97, 102, 233])>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_decode(b, \"UTF-8\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **OTHER DATA STRUCTURES:**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **STRING ARRAYS:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'hello world'>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(b\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'caf\\xc3\\xa9'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(\"café\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([ 99,  97, 102, 233])>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = tf.constant([ord(c) for c in \"café\"])\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'caf\\xc3\\xa9'>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tf.strings.unicode_encode(u, \"UTF-8\")\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=4>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.length(b, unit=\"UTF8_CHAR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([ 99,  97, 102, 233])>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_decode(b, \"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = tf.constant([\"Café\", \"Coffee\", \"caffè\", \"咖啡\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([4, 6, 5, 2])>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.length(p, unit=\"UTF8_CHAR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[67, 97, 102, 233], [67, 111, 102, 102, 101, 101],\n",
       " [99, 97, 102, 102, 232], [21654, 21857]]>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = tf.strings.unicode_decode(p, \"UTF8\")\n",
    "r"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **RAGGED TENSORS:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6,), dtype=int32, numpy=array([ 67, 111, 102, 102, 101, 101])>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[67, 111, 102, 102, 101, 101], [99, 97, 102, 102, 232]]>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[1:3]  # extra code – a slice of a ragged tensor is a ragged tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[67, 97, 102, 233], [67, 111, 102, 102, 101, 101],\n",
       " [99, 97, 102, 102, 232], [21654, 21857], [65, 66], [], [67]]>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2 = tf.ragged.constant([[65, 66], [], [67]])\n",
    "tf.concat([r, r2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[67, 97, 102, 233, 68, 69, 70], [67, 111, 102, 102, 101, 101, 71],\n",
      " [99, 97, 102, 102, 232], [21654, 21857, 72, 73]]>\n"
     ]
    }
   ],
   "source": [
    "r3 = tf.ragged.constant([[68, 69, 70], [71], [], [72, 73]])\n",
    "print(tf.concat([r, r3], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 6), dtype=int32, numpy=\n",
       "array([[   67,    97,   102,   233,     0,     0],\n",
       "       [   67,   111,   102,   102,   101,   101],\n",
       "       [   99,    97,   102,   102,   232,     0],\n",
       "       [21654, 21857,     0,     0,     0,     0]])>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.to_tensor()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **SPARSE TENSORS:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = tf.SparseTensor(\n",
    "    indices=[[0, 1], [1, 0], [2, 3]], values=[1.0, 2.0, 3.0], dense_shape=[3, 4]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
       "array([[0., 1., 0., 0.],\n",
       "       [2., 0., 0., 0.],\n",
       "       [0., 0., 0., 3.]], dtype=float32)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sparse.to_dense(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseTensor(indices=tf.Tensor(\n",
       "[[0 1]\n",
       " [1 0]\n",
       " [2 3]], shape=(3, 2), dtype=int64), values=tf.Tensor([ 42.  84. 126.], shape=(3,), dtype=float32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s * 42.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsupported operand type(s) for +: 'SparseTensor' and 'float'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    s + 42.0\n",
    "except TypeError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[ 30.,  40.],\n",
       "       [ 20.,  40.],\n",
       "       [210., 240.]], dtype=float32)>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – shows how to multiply a sparse tensor and a dense tensor\n",
    "s4 = tf.constant([[10., 20.], [30., 40.], [50., 60.], [70., 80.]])\n",
    "tf.sparse.sparse_dense_matmul(s, s4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{{function_node __wrapped__SparseToDense_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[1] = [0,1] is out of order. Many sparse ops require sorted indices.\n",
      "    Use `tf.sparse.reorder` to create a correctly ordered copy.\n",
      "\n",
      " [Op:SparseToDense]\n"
     ]
    }
   ],
   "source": [
    "# extra code – when creating a sparse tensor, values must be given in \"reading\n",
    "#              order\", or else `to_dense()` will fail.\n",
    "s5 = tf.SparseTensor(indices=[[0, 2], [0, 1]],  # WRONG ORDER!\n",
    "                     values=[1., 2.],\n",
    "                     dense_shape=[3, 4])\n",
    "try:\n",
    "    tf.sparse.to_dense(s5)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
       "array([[0., 2., 1., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – shows how to fix the sparse tensor s5 by reordering its values\n",
    "s6 = tf.sparse.reorder(s5)\n",
    "tf.sparse.to_dense(s6)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **TENSOR ARRAYS:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = tf.TensorArray(dtype=tf.float32, size=3)\n",
    "array = array.write(0, tf.constant([1., 2.]))\n",
    "array = array.write(1, tf.constant([3., 10.]))\n",
    "array = array.write(2, tf.constant([5., 7.]))\n",
    "tensor1 = array.read(1)  # returns (and zeros out!) tf.constant([3., 10.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[1., 2.],\n",
       "       [0., 0.],\n",
       "       [5., 7.]], dtype=float32)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[ 1.,  2.],\n",
       "       [ 3., 10.],\n",
       "       [ 5.,  7.]], dtype=float32)>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – shows how to disable clear_after_read\n",
    "array2 = tf.TensorArray(dtype=tf.float32, size=3, clear_after_read=False)\n",
    "array2 = array2.write(0, tf.constant([1., 2.]))\n",
    "array2 = array2.write(1, tf.constant([3., 10.]))\n",
    "array2 = array2.write(2, tf.constant([5., 7.]))\n",
    "tensor2 = array2.read(1)  # returns tf.constant([3., 10.])\n",
    "array2.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[1., 2.],\n",
       "       [0., 0.],\n",
       "       [5., 7.]], dtype=float32)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – shows how to create and use a tensor array with a dynamic size\n",
    "array3 = tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True)\n",
    "array3 = array3.write(0, tf.constant([1., 2.]))\n",
    "array3 = array3.write(1, tf.constant([3., 10.]))\n",
    "array3 = array3.write(2, tf.constant([5., 7.]))\n",
    "tensor3 = array3.read(1)\n",
    "array3.stack()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **SETS:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseTensor(indices=tf.Tensor(\n",
       "[[0 0]\n",
       " [0 1]\n",
       " [0 2]\n",
       " [0 3]\n",
       " [0 4]], shape=(5, 2), dtype=int64), values=tf.Tensor([ 1  5  6  9 11], shape=(5,), dtype=int32), dense_shape=tf.Tensor([1 5], shape=(2,), dtype=int64))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([[1, 5, 9]])\n",
    "b = tf.constant([[5, 6, 9, 11]])\n",
    "u = tf.sets.union(a, b)\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 5), dtype=int32, numpy=array([[ 1,  5,  6,  9, 11]])>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sparse.to_dense(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 5), dtype=int32, numpy=\n",
       "array([[ 1,  5,  6,  9, 11],\n",
       "       [ 0, 10, 13,  0,  0]])>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([[1, 5, 9], [10, 0, 0]])\n",
    "b = tf.constant([[5, 6, 9, 11], [13, 0, 0, 0]])\n",
    "u = tf.sets.union(a, b)\n",
    "tf.sparse.to_dense(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 5), dtype=int32, numpy=\n",
       "array([[ 1,  5,  6,  9, 11],\n",
       "       [-1, 10, 13, -1, -1]])>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – shows how to use a different default value: -1 in this case\n",
    "a = tf.constant([[1, 5, 9], [10, -1, -1]])\n",
    "b = tf.constant([[5, 6, 9, 11], [13, -1, -1, -1]])\n",
    "u = tf.sets.union(a, b)\n",
    "tf.sparse.to_dense(u, default_value=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[2, 3, 7],\n",
       "       [7, 0, 0]])>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – shows how to use `tf.sets.difference()`\n",
    "set1 = tf.constant([[2, 3, 5, 7], [7, 9, 0, 0]])\n",
    "set2 = tf.constant([[4, 5, 6], [9, 10, 0]])\n",
    "tf.sparse.to_dense(tf.sets.difference(set1, set2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[5, 0],\n",
       "       [0, 9]])>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – shows how to use `tf.sets.difference()`\n",
    "tf.sparse.to_dense(tf.sets.intersection(set1, set2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – check whether set1[0] contains 5\n",
    "tf.sets.size(tf.sets.intersection(set1[:1], tf.constant([[5, 0, 0, 0]]))) > 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **QUEUES:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=2>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = tf.queue.FIFOQueue(3, [tf.int32, tf.string], shapes=[(), ()])\n",
    "q.enqueue([10, b\"windy\"])\n",
    "q.enqueue([15, b\"sunny\"])\n",
    "q.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=int32, numpy=10>,\n",
       " <tf.Tensor: shape=(), dtype=string, numpy=b'windy'>]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.dequeue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "q.enqueue_many([[13, 16], [b'cloudy', b'rainy']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(3,), dtype=int32, numpy=array([15, 13, 16])>,\n",
       " <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'sunny', b'cloudy', b'rainy'], dtype=object)>]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.dequeue_many(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **CUSTOM LOSS FUNCTION:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_fn(y_true, y_pred):\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = tf.abs(error) < 1\n",
    "    squared_loss = tf.square(error) / 2\n",
    "    linear_loss = tf.abs(error) - 0.5\n",
    "    return tf.where(is_small_error, squared_loss, linear_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x252 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# extra code – shows what the Huber loss looks like\n",
    "\n",
    "plt.figure(figsize=(8, 3.5))\n",
    "z = np.linspace(-4, 4, 200)\n",
    "z_center = np.linspace(-1, 1, 200)\n",
    "plt.plot(z, huber_fn(0, z), \"b-\", linewidth=2, label=\"huber($z$)\")\n",
    "plt.plot(z, z ** 2 / 2, \"r:\", linewidth=1)\n",
    "plt.plot(z_center, z_center ** 2 / 2, \"r\", linewidth=2)\n",
    "plt.plot([-1, -1], [0, huber_fn(0., -1.)], \"k--\")\n",
    "plt.plot([1, 1], [0, huber_fn(0., 1.)], \"k--\")\n",
    "plt.gca().axhline(y=0, color='k')\n",
    "plt.gca().axvline(x=0, color='k')\n",
    "plt.text(2.1, 3.5, r\"$\\frac{1}{2}z^2$\", color=\"r\", fontsize=15)\n",
    "plt.text(3.0, 2.2, r\"$|z| - \\frac{1}{2}$\", color=\"b\", fontsize=15)\n",
    "plt.axis([-4, 4, 0, 4])\n",
    "plt.xlabel(\"$z$\")\n",
    "plt.legend(fontsize=14)\n",
    "plt.title(\"Huber loss\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test our custom loss function, let's create a basic Keras model and train it on the California housing dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target.reshape(-1, 1), random_state=42\n",
    ")\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(\n",
    "            30,\n",
    "            activation=\"relu\",\n",
    "            kernel_initializer=\"he_normal\",\n",
    "            input_shape=input_shape,\n",
    "        ),\n",
    "        tf.keras.layers.Dense(1),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=huber_fn, optimizer=\"nadam\", metrics=[\"mae\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4659 - mae: 0.8215 - val_loss: 0.3293 - val_mae: 0.6501\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2688 - mae: 0.5794 - val_loss: 0.2261 - val_mae: 0.5211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21342fb6e90>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2, validation_data=(X_valid_scaled, y_valid))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **SAVING/LOADING MODELS WITH CUSTOM OBJECTS:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/my_model_with_a_custom_loss\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/my_model_with_a_custom_loss\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"models/my_model_with_a_custom_loss\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\n",
    "    \"models/my_model_with_a_custom_loss\", custom_objects={\"huber_fn\": huber_fn}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_huber(threshold=1.0):\n",
    "    def huber_fn(y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss = threshold * tf.abs(error) - threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "\n",
    "    return huber_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=create_huber(2.0), optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2455 - mae: 0.5095 - val_loss: 0.2214 - val_mae: 0.4740\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2144 - mae: 0.4762 - val_loss: 0.2197 - val_mae: 0.4691\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21347942bc0>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2, validation_data=(X_valid_scaled, y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/my_model_with_a_custom_loss_threshold_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/my_model_with_a_custom_loss_threshold_2\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"models/my_model_with_a_custom_loss_threshold_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\n",
    "    \"models/my_model_with_a_custom_loss_threshold_2\",\n",
    "    custom_objects={\"huber_fn\": create_huber(2.0)},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2028 - mae: 0.4618 - val_loss: 0.1903 - val_mae: 0.4406\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.1949 - mae: 0.4513 - val_loss: 0.1912 - val_mae: 0.4447\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21349c7dcc0>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2, validation_data=(X_valid_scaled, y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < self.threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss = self.threshold * tf.abs(error) - self.threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {\n",
    "            **base_config,\n",
    "            \"threshold\": self.threshold,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra code – creates another basic Keras model\n",
    "tf.random.set_seed(42)\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(\n",
    "            30,\n",
    "            activation=\"relu\",\n",
    "            kernel_initializer=\"he_normal\",\n",
    "            input_shape=input_shape,\n",
    "        ),\n",
    "        tf.keras.layers.Dense(1),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=HuberLoss(2.), optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 2s 2ms/step - loss: 0.7321 - mae: 0.9161 - val_loss: 0.6816 - val_mae: 0.8105\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3450 - mae: 0.6104 - val_loss: 0.4059 - val_mae: 0.6058\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2134ae71ae0>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2, validation_data=(X_valid_scaled, y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/my_model_with_a_custom_loss_class\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/my_model_with_a_custom_loss_class\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"models/my_model_with_a_custom_loss_class\")  # extra code – saving works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\n",
    "    \"models/my_model_with_a_custom_loss_class\", custom_objects={\"HuberLoss\": HuberLoss}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2505 - mae: 0.5154 - val_loss: 0.2579 - val_mae: 0.4896\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2159 - mae: 0.4769 - val_loss: 0.2174 - val_mae: 0.4632\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2134bf9fd90>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – shows that loading worked fine, the model can be used normally\n",
    "model.fit(X_train_scaled, y_train, epochs=2, validation_data=(X_valid_scaled, y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.loss.threshold  # extra code – the treshold was loaded correctly"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **OTHER CUSTOM FUNCTIONS:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_softplus(z):\n",
    "    return tf.math.log(1.0 + tf.exp(z))\n",
    "\n",
    "\n",
    "def my_glorot_initializer(shape, dtype=tf.float32):\n",
    "    stddev = tf.sqrt(2.0 / (shape[0] + shape[1]))\n",
    "    return tf.random.normal(shape, stddev=stddev, dtype=dtype)\n",
    "\n",
    "\n",
    "def my_l1_regularizer(weights):\n",
    "    return tf.reduce_sum(tf.abs(0.01 * weights))\n",
    "\n",
    "\n",
    "def my_positive_weights(weights):  # return value is just tf.nn.relu(weights)\n",
    "    return tf.where(weights < 0.0, tf.zeros_like(weights), weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = tf.keras.layers.Dense(\n",
    "    1,\n",
    "    activation=my_softplus,\n",
    "    kernel_initializer=my_glorot_initializer,\n",
    "    kernel_regularizer=my_l1_regularizer,\n",
    "    kernel_constraint=my_positive_weights,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.4734 - mae: 0.7876 - val_loss: inf - val_mae: inf\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.8986 - mae: 0.6008 - val_loss: inf - val_mae: inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/my_model_with_a_custom_parts\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/my_model_with_a_custom_parts\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6423 - mae: 0.5389 - val_loss: inf - val_mae: inf\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5505 - mae: 0.5056 - val_loss: inf - val_mae: inf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2134d426830>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – show that building, training, saving, loading, and training again\n",
    "#              works fine with a model containing many custom parts\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(\n",
    "            30,\n",
    "            activation=\"relu\",\n",
    "            kernel_initializer=\"he_normal\",\n",
    "            input_shape=input_shape,\n",
    "        ),\n",
    "        tf.keras.layers.Dense(\n",
    "            1,\n",
    "            activation=my_softplus,\n",
    "            kernel_initializer=my_glorot_initializer,\n",
    "            kernel_regularizer=my_l1_regularizer,\n",
    "            kernel_constraint=my_positive_weights,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[\"mae\"])\n",
    "model.fit(X_train_scaled, y_train, epochs=2, validation_data=(X_valid_scaled, y_valid))\n",
    "model.save(\"models/my_model_with_a_custom_parts\")\n",
    "model = tf.keras.models.load_model(\n",
    "    \"models/my_model_with_a_custom_parts\",\n",
    "    custom_objects={\n",
    "        \"my_l1_regularizer\": my_l1_regularizer,\n",
    "        \"my_positive_weights\": my_positive_weights,\n",
    "        \"my_glorot_initializer\": my_glorot_initializer,\n",
    "        \"my_softplus\": my_softplus,\n",
    "    },\n",
    ")\n",
    "model.fit(X_train_scaled, y_train, epochs=2, validation_data=(X_valid_scaled, y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyL1Regularizer(tf.keras.regularizers.Regularizer):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "\n",
    "    def __call__(self, weights):\n",
    "        return tf.reduce_sum(tf.abs(self.factor * weights))\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\"factor\": self.factor}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.2775 - mae: 0.7328 - val_loss: inf - val_mae: inf\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8134 - mae: 0.5776 - val_loss: inf - val_mae: inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/my_model_with_many_custom_parts\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/my_model_with_many_custom_parts\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6073 - mae: 0.5257 - val_loss: inf - val_mae: inf\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5321 - mae: 0.4993 - val_loss: inf - val_mae: inf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21350a27eb0>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(\n",
    "            30,\n",
    "            activation=\"relu\",\n",
    "            kernel_initializer=\"he_normal\",\n",
    "            input_shape=input_shape,\n",
    "        ),\n",
    "        tf.keras.layers.Dense(\n",
    "            1,\n",
    "            activation=my_softplus,\n",
    "            kernel_regularizer=MyL1Regularizer(0.01),\n",
    "            kernel_constraint=my_positive_weights,\n",
    "            kernel_initializer=my_glorot_initializer,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[\"mae\"])\n",
    "model.fit(X_train_scaled, y_train, epochs=2, validation_data=(X_valid_scaled, y_valid))\n",
    "model.save(\"models/my_model_with_many_custom_parts\")\n",
    "model = tf.keras.models.load_model(\n",
    "    \"models/my_model_with_many_custom_parts\",\n",
    "    custom_objects={\n",
    "        \"MyL1Regularizer\": MyL1Regularizer,\n",
    "        \"my_positive_weights\": my_positive_weights,\n",
    "        \"my_glorot_initializer\": my_glorot_initializer,\n",
    "        \"my_softplus\": my_softplus,\n",
    "    },\n",
    ")\n",
    "model.fit(X_train_scaled, y_train, epochs=2, validation_data=(X_valid_scaled, y_valid))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **CUSTOM METRICS:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra code – once again, lets' create a basic Keras model\n",
    "tf.random.set_seed(42)\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(\n",
    "            30,\n",
    "            activation=\"relu\",\n",
    "            kernel_initializer=\"he_normal\",\n",
    "            input_shape=input_shape,\n",
    "        ),\n",
    "        tf.keras.layers.Dense(1),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[create_huber(2.0)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 960us/step - loss: 1.3273 - huber_fn: 0.5815\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 956us/step - loss: 0.6065 - huber_fn: 0.2923\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2134d336110>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – train the model with our custom metric\n",
    "model.fit(X_train_scaled, y_train, epochs=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: if you use the same function as the loss and a metric, you may be surprised to see slightly different results. This is in part because the operations are not computed exactly in the same order, so there might be tiny floating point errors. More importantly, if you use sample weights or class weights, then the equations are a bit different:\n",
    "* the `fit()` method keeps track of the mean of all batch losses seen so far since the start of the epoch. Each batch loss is the sum of the weighted instance losses divided by the _batch size_ (not the sum of weights, so the batch loss is _not_ the weighted mean of the losses).\n",
    "* the metric since the start of the epoch is equal to the sum of weighted instance losses divided by sum of all weights seen so far. In other words, it is the weighted mean of all the instance losses. Not the same thing."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **STREAMING METRICS:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.8>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = tf.keras.metrics.Precision()\n",
    "precision([0, 1, 1, 1, 0, 1, 0, 1], [1, 1, 0, 1, 0, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision([0, 1, 0, 0, 1, 0, 1, 1], [1, 0, 1, 1, 0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'true_positives:0' shape=(1,) dtype=float32, numpy=array([4.], dtype=float32)>,\n",
       " <tf.Variable 'false_positives:0' shape=(1,) dtype=float32, numpy=array([4.], dtype=float32)>]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision.reset_states()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a streaming metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberMetric(tf.keras.metrics.Metric):\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.threshold = threshold\n",
    "        self.huber_fn = create_huber(threshold)\n",
    "        self.total = self.add_weight(\"total\", initializer=\"zeros\")\n",
    "        self.count = self.add_weight(\"total\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        sample_metrics = self.huber_fn(y_true, y_pred)\n",
    "        self.total.assign_add(tf.reduce_sum(sample_metrics))\n",
    "        self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))\n",
    "\n",
    "    def result(self):\n",
    "        return self.total / self.count\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extra material** – the rest of this section tests the `HuberMetric` class and shows another implementation subclassing `tf.keras.metrics.Mean`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=14.0>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = HuberMetric(threshold=2.0)\n",
    "\n",
    "# total = 2 * |10 - 2| - 2²/2 = 14\n",
    "# count = 1\n",
    "# result = 14 / 1 = 14\n",
    "m(tf.constant([[2.0]]), tf.constant([[10.0]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=7.0>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total = total + (|1 - 0|² / 2) + (2 * |9.25 - 5| - 2² / 2) = 14 + 7 = 21\n",
    "# count = count + 2 = 3\n",
    "# result = total / count = 21 / 3 = 7\n",
    "m(tf.constant([[0.0], [5.0]]), tf.constant([[1.0], [9.25]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=7.0>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'total:0' shape=() dtype=float32, numpy=21.0>,\n",
       " <tf.Variable 'total:0' shape=() dtype=float32, numpy=3.0>]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'total:0' shape=() dtype=float32, numpy=0.0>,\n",
       " <tf.Variable 'total:0' shape=() dtype=float32, numpy=0.0>]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.reset_states()\n",
    "m.variables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that the `HuberMetric` class works well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(\n",
    "            30,\n",
    "            activation=\"relu\",\n",
    "            kernel_initializer=\"he_normal\",\n",
    "            input_shape=input_shape,\n",
    "        ),\n",
    "        tf.keras.layers.Dense(1),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=create_huber(2.0), optimizer=\"nadam\", metrics=[HuberMetric(2.0)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.8550 - huber_metric_1: 0.8550\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3164 - huber_metric_1: 0.3164\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2134bfdddb0>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/my_model_with_a_custom_metric\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/my_model_with_a_custom_metric\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"models/my_model_with_a_custom_metric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\n",
    "    \"models/my_model_with_a_custom_metric\",\n",
    "    custom_objects={\"huber_fn\": create_huber(2.0), \"HuberMetric\": HuberMetric},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2512 - huber_metric_1: 0.2512\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2172 - huber_metric_1: 0.2172\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21351df9b70>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`model.metrics` contains the model's loss followed by the model's metric(s), so the `HuberMetric` is `model.metrics[-1]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics[-1].threshold"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like it works fine! More simply, we could have created the class like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberMetric(tf.keras.metrics.Mean):\n",
    "    def __init__(self, threshold=1.0, name=\"HuberMetric\", dtype=None):\n",
    "        self.threshold = threshold\n",
    "        self.huber_fn = create_huber(threshold)\n",
    "        super().__init__(name=name, dtype=dtype)\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        metric = self.huber_fn(y_true, y_pred)\n",
    "        super(HuberMetric, self).update_state(metric, sample_weight)\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class handles shapes better, and it also supports sample weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(\n",
    "            30,\n",
    "            activation=\"relu\",\n",
    "            kernel_initializer=\"he_normal\",\n",
    "            input_shape=input_shape,\n",
    "        ),\n",
    "        tf.keras.layers.Dense(1),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.Huber(2.0),\n",
    "    optimizer=\"nadam\",\n",
    "    weighted_metrics=[HuberMetric(2.0)],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 997us/step - loss: 0.3402 - HuberMetric: 0.6856\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.1417 - HuberMetric: 0.2854\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "sample_weight = np.random.rand(len(y_train))\n",
    "history = model.fit(X_train_scaled, y_train, epochs=2, sample_weight=sample_weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3402365744113922, 0.34023662366424096)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(history.history[\"loss\"][0], history.history[\"HuberMetric\"][0] * sample_weight.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/my_model_with_a_custom_metric_v2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/my_model_with_a_custom_metric_v2\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"models/my_model_with_a_custom_metric_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\n",
    "    \"models/my_model_with_a_custom_metric_v2\",\n",
    "    custom_objects={\"HuberMetric\": HuberMetric},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2271 - HuberMetric: 0.2271\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2091 - HuberMetric: 0.2091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x213542d59c0>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics[-1].threshold"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **CUSTOM LAYERS:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "exponential_layer = tf.keras.layers.Lambda(lambda x: tf.exp(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.36787945, 1.        , 2.7182817 ], dtype=float32)>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – like all layers, it can be used as a function:\n",
    "exponential_layer([-1., 0., 1.])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding an exponential layer at the output of a regression model can be useful if the values to predict are positive and with very different scales (e.g., 0.001, 10., 10000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.8255 - val_loss: 0.4356\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7617 - val_loss: 0.4576\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4628 - val_loss: 0.3897\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4164 - val_loss: 0.3695\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4008 - val_loss: 0.3656\n",
      "162/162 [==============================] - 0s 808us/step - loss: 0.3842\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3841632604598999"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(30, activation=\"relu\", input_shape=input_shape),\n",
    "        tf.keras.layers.Dense(1),\n",
    "        exponential_layer,\n",
    "    ]\n",
    ")\n",
    "model.compile(loss=\"mse\", optimizer=\"sgd\")\n",
    "model.fit(X_train_scaled, y_train, epochs=5, validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, it's often preferable to replace the targets with the logarithm of the targets (and use no activation function in the output layer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        self.kernel = self.add_weight(\n",
    "            name=\"kernel\",\n",
    "            shape=[batch_input_shape[-1], self.units],\n",
    "            initializer=\"he_normal\",\n",
    "        )\n",
    "        self.bias = self.add_weight(\n",
    "            name=\"bias\",\n",
    "            shape=[self.units],\n",
    "            initializer=\"zeros\",\n",
    "        )\n",
    "        super().build(batch_input_shape)  # must be at the end\n",
    "\n",
    "    def call(self, X):\n",
    "        return self.activation(X @ self.kernel + self.bias)\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return tf.TensorShape(batch_input_shape.as_list()[:-1] + [self.units])\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {\n",
    "            **base_config,\n",
    "            \"units\": self.units,\n",
    "            \"activation\": tf.keras.activations.serialize(self.activation),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 2.4657 - val_loss: 0.8865\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7297 - val_loss: 0.6684\n",
      "162/162 [==============================] - 0s 781us/step - loss: 0.6360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/my_model_with_a_custom_layer\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/my_model_with_a_custom_layer\\assets\n"
     ]
    }
   ],
   "source": [
    "# extra code – shows that a custom layer can be used normally\n",
    "tf.random.set_seed(42)\n",
    "model = tf.keras.Sequential(\n",
    "    [MyDense(30, activation=\"relu\", input_shape=input_shape), MyDense(1)]\n",
    ")\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "model.fit(X_train_scaled, y_train, epochs=2, validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test)\n",
    "model.save(\"models/my_model_with_a_custom_layer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5529 - val_loss: 0.5723\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4529 - val_loss: 0.6136\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2135bd78d60>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – shows how to load a model with a custom layer\n",
    "model = tf.keras.models.load_model(\n",
    "    \"models/my_model_with_a_custom_layer\", custom_objects={\"MyDense\": MyDense}\n",
    ")\n",
    "model.fit(X_train_scaled, y_train, epochs=2, validation_data=(X_valid_scaled, y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMultiLayer(tf.keras.layers.Layer):\n",
    "    def call(self, X):\n",
    "        X1, X2 = X\n",
    "        print(\"X1.shape: \", X1.shape, \" X2.shape: \", X2.shape)  # extra code\n",
    "        return X1 + X2, X1 * X2, X1 / X2\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        batch_input_shape1, batch_input_shape2 = batch_input_shape\n",
    "        return [batch_input_shape1, batch_input_shape1, batch_input_shape1]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our custom layer can be called using the functional API like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1.shape:  (None, 2)  X2.shape:  (None, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<KerasTensor: shape=(None, 2) dtype=float32 (created by layer 'my_multi_layer')>,\n",
       " <KerasTensor: shape=(None, 2) dtype=float32 (created by layer 'my_multi_layer')>,\n",
       " <KerasTensor: shape=(None, 2) dtype=float32 (created by layer 'my_multi_layer')>)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – tests MyMultiLayer with symbolic inputs\n",
    "inputs1 = tf.keras.layers.Input(shape=[2])\n",
    "inputs2 = tf.keras.layers.Input(shape=[2])\n",
    "MyMultiLayer()((inputs1, inputs2))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `call()` method receives symbolic inputs, and it returns symbolic outputs. The shapes are only partially specified at this stage: we don't know the batch size, which is why the first dimension is `None`.\n",
    "\n",
    "We can also pass actual data to the custom layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1.shape:  (2, 2)  X2.shape:  (2, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       " array([[ 9., 18.],\n",
       "        [ 6., 10.]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       " array([[18., 72.],\n",
       "        [ 8., 21.]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       " array([[0.5      , 0.5      ],\n",
       "        [0.5      , 2.3333333]], dtype=float32)>)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – tests MyMultiLayer with actual data \n",
    "X1, X2 = np.array([[3., 6.], [2., 7.]]), np.array([[6., 12.], [4., 3.]]) \n",
    "MyMultiLayer()((X1, X2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a layer with a different behavior during training and testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGaussianNoise(tf.keras.layers.Layer):\n",
    "    def __init__(self, stddev, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.stddev = stddev\n",
    "\n",
    "    def call(self, X, training=None):\n",
    "        if training:\n",
    "            noise = tf.random.normal(tf.shape(X), stddev=self.stddev)\n",
    "            return X + noise\n",
    "        return X\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return batch_input_shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.5730 - val_loss: 4.9438\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.2828 - val_loss: 1.6412\n",
      "162/162 [==============================] - 0s 848us/step - loss: 1.0146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0146161317825317"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – tests MyGaussianNoise\n",
    "tf.random.set_seed(42)\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        MyGaussianNoise(stddev=1.0, input_shape=input_shape),\n",
    "        tf.keras.layers.Dense(30, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "        tf.keras.layers.Dense(1),\n",
    "    ]\n",
    ")\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "model.fit(X_train_scaled, y_train, epochs=2, validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **CUSTOM MODELS:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, n_layers, n_neurons, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [\n",
    "            tf.keras.layers.Dense(\n",
    "                n_neurons, activation=\"relu\", kernel_initializer=\"he_normal\"\n",
    "            )\n",
    "            for _ in range(n_layers)\n",
    "        ]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        return inputs + Z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualRegressor(tf.keras.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = tf.keras.layers.Dense(\n",
    "            30, activation=\"relu\", kernel_initializer=\"he_normal\"\n",
    "        )\n",
    "        self.block1 = ResidualBlock(2, 30)\n",
    "        self.block2 = ResidualBlock(2, 30)\n",
    "        self.out = tf.keras.layers.Dense(output_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = self.hidden1(inputs)\n",
    "        for _ in range(1 + 3):\n",
    "            Z = self.block1(Z)\n",
    "        Z = self.block2(Z)\n",
    "        return self.out(Z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 4s 2ms/step - loss: 7.8650\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.1069\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.7043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, dense_34_layer_call_fn, dense_34_layer_call_and_return_conditional_losses, dense_35_layer_call_fn, dense_35_layer_call_and_return_conditional_losses while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/my_custom_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/my_custom_model\\assets\n"
     ]
    }
   ],
   "source": [
    "# extra code – shows that the model can be used normally\n",
    "tf.random.set_seed(42)\n",
    "model = ResidualRegressor(1)\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=2)\n",
    "score = model.evaluate(X_test_scaled, y_test)\n",
    "model.save(\"models/my_custom_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 3s 2ms/step - loss: 0.9227\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 2.6391\n",
      "1/1 [==============================] - 0s 77ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.43191978],\n",
       "       [1.6120689 ],\n",
       "       [4.171667  ]], dtype=float32)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – the model can be loaded and you can continue training or use it\n",
    "#              to make predictions\n",
    "model = tf.keras.models.load_model(\"models/my_custom_model\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=2)\n",
    "model.predict(X_test_scaled[:3])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could have defined the model using the sequential API instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "block1 = ResidualBlock(2, 30)\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(30, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "        block1,\n",
    "        block1,\n",
    "        block1,\n",
    "        block1,\n",
    "        ResidualBlock(2, 30),\n",
    "        tf.keras.layers.Dense(1),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **LOSSES AND METRICS BASED ON MODEL INTERNALS:**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning**: due to an issue introduced in TF 2.2 ([#46858](https://github.com/tensorflow/tensorflow/issues/46858)), `super().build()` fails. We can work around this issue by setting `self.built = True` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReconstructingRegressor(tf.keras.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [\n",
    "            tf.keras.layers.Dense(30, activation=\"relu\", kernel_initializer=\"he_normal\")\n",
    "            for _ in range(5)\n",
    "        ]\n",
    "        self.out = tf.keras.layers.Dense(output_dim)\n",
    "        self.reconstruction_mean = tf.keras.metrics.Mean(name=\"reconstruction_error\")\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        n_inputs = batch_input_shape[-1]\n",
    "        self.reconstruct = tf.keras.layers.Dense(n_inputs)\n",
    "        self.built = True  # WORKAROUND for super().build(batch_input_shape)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        reconstruction = self.reconstruct(Z)\n",
    "        recon_loss = tf.reduce_mean(tf.square(reconstruction - inputs))\n",
    "        self.add_loss(0.05 * recon_loss)\n",
    "        if training:\n",
    "            result = self.reconstruction_mean(recon_loss)\n",
    "            self.add_metric(result)\n",
    "        return self.out(Z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 3s 2ms/step - loss: 0.8134 - reconstruction_error: 1.2368\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4868 - reconstruction_error: 0.6191\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4469 - reconstruction_error: 0.4568\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3808 - reconstruction_error: 0.3674\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3612 - reconstruction_error: 0.3032\n",
      "162/162 [==============================] - 0s 863us/step\n"
     ]
    }
   ],
   "source": [
    "# extra code\n",
    "tf.random.set_seed(42)\n",
    "model = ReconstructingRegressor(1)\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=5)\n",
    "y_pred = model.predict(X_test_scaled)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **COMPUTING GRADIENTS USING AUTODIFF:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(w1, w2):\n",
    "    return 3 * w1 ** 2 + 2 * w1 * w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.000003007075065"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1, w2 = 5, 3\n",
    "eps = 1e-6\n",
    "(f(w1 + eps, w2) - f(w1, w2)) / eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.000000003174137"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(f(w1, w2 + eps) - f(w1, w2)) / eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1, w2 = tf.Variable(5.0), tf.Variable(3.0)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "gradients = tape.gradient(z, [w1, w2])\n",
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A non-persistent GradientTape can only be used to compute one set of gradients (or jacobians)\n"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "dz_dw1 = tape.gradient(z, w1)  # returns tensor 36.0\n",
    "try:\n",
    "    dz_dw2 = tape.gradient(z, w2)  # raises a RuntimeError!\n",
    "except RuntimeError as ex:\n",
    "    print(ex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "dz_dw1 = tape.gradient(z, w1)  # returns tensor 36.0\n",
    "dz_dw2 = tape.gradient(z, w2)  # returns tensor 10.0, works fine now!\n",
    "del tape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1, c2 = tf.constant(5.0), tf.constant(3.0)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(c1, c2)\n",
    "\n",
    "gradients = tape.gradient(z, [c1, c2])\n",
    "gradients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(c1)\n",
    "    tape.watch(c2)\n",
    "    z = f(c1, c2)\n",
    "\n",
    "gradients = tape.gradient(z, [c1, c2])\n",
    "gradients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=136.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=30.0>]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – if given a vector, tape.gradient() will compute the gradient of\n",
    "#              the vector's sum.\n",
    "with tf.GradientTape() as tape:\n",
    "    z1 = f(w1, w2 + 2.0)\n",
    "    z2 = f(w1, w2 + 5.0)\n",
    "    z3 = f(w1, w2 + 7.0)\n",
    "\n",
    "tape.gradient([z1, z2, z3], [w1, w2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=136.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=30.0>]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – shows that we get the same result as the previous cell\n",
    "with tf.GradientTape() as tape:\n",
    "    z1 = f(w1, w2 + 2.0)\n",
    "    z2 = f(w1, w2 + 5.0)\n",
    "    z3 = f(w1, w2 + 7.0)\n",
    "    z = z1 + z2 + z3\n",
    "\n",
    "tape.gradient(z, [w1, w2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra code – shows how to compute the jacobians and the hessians\n",
    "with tf.GradientTape(persistent=True) as hessian_tape:\n",
    "    with tf.GradientTape() as jacobian_tape:\n",
    "        z = f(w1, w2)\n",
    "    jacobians = jacobian_tape.gradient(z, [w1, w2])\n",
    "hessians = [hessian_tape.gradient(jacobian, [w1, w2]) for jacobian in jacobians]\n",
    "del hessian_tape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<tf.Tensor: shape=(), dtype=float32, numpy=6.0>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=2.0>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=2.0>, None]]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hessians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=30.0>, None]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(w1, w2):\n",
    "    return 3 * w1**2 + tf.stop_gradient(2 * w1 * w2)\n",
    "\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)  # same result as without stop_gradient()\n",
    "\n",
    "gradients = tape.gradient(z, [w1, w2])\n",
    "gradients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=inf>]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable(1e-50)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = tf.sqrt(x)\n",
    "\n",
    "tape.gradient(z, [x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=30.0>"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.log(tf.exp(tf.constant(30.0, dtype=tf.float32)) + 1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_softplus(z):\n",
    "    return tf.math.log(1 + tf.exp(-tf.abs(z))) + tf.maximum(0., z)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the proof that this equation is equal to log(1 + exp(_z_)):\n",
    "* softplus(_z_) = log(1 + exp(_z_))\n",
    "* softplus(_z_) = log(1 + exp(_z_)) - log(exp(_z_)) + log(exp(_z_)) ; **just adding and subtracting the same value**\n",
    "* softplus(_z_) = log\\[(1 + exp(_z_)) / exp(_z_)\\] + log(exp(_z_)) ; **since log(_a_) - log(_b_) = log(_a_ / _b_)**\n",
    "* softplus(_z_) = log\\[(1 + exp(_z_)) / exp(_z_)\\] + _z_ ; **since log(exp(_z_)) = _z_**\n",
    "* softplus(_z_) = log\\[1 / exp(_z_) + exp(_z_) / exp(_z_)\\] + _z_ ; **since (1 + _a_) / _b_ = 1 / _b_ + _a_ / _b_**\n",
    "* softplus(_z_) = log\\[exp(–_z_) + 1\\] + _z_ ; **since 1 / exp(_z_) = exp(–z), and exp(_z_) / exp(_z_) = 1**\n",
    "* softplus(_z_) = softplus(–_z_) + _z_ ; **we recognize the definition at the top, but with –_z_**\n",
    "* softplus(_z_) = softplus(–|_z_|) + max(0, _z_) ; **if you consider both cases, _z_ < 0 or _z_ ≥ 0, you will see that this works**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable([1.0e30])\n",
    "with tf.GradientTape() as tape:\n",
    "    z = my_softplus(x)\n",
    "\n",
    "tape.gradient(z, [x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.custom_gradient\n",
    "def my_softplus(z):\n",
    "    def my_softplus_gradients(grads):  # grads = backprop'ed from upper layers\n",
    "        return grads * (1 - 1 / (1 + tf.exp(z)))  # stable grads of softplus\n",
    "\n",
    "    result = tf.math.log(1 + tf.exp(-tf.abs(z))) + tf.maximum(0.0, z)\n",
    "    return result, my_softplus_gradients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1000.], dtype=float32)>,\n",
       " [<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – shows that the function is now stable, as well as its gradients\n",
    "x = tf.Variable([1000.0])\n",
    "with tf.GradientTape() as tape:\n",
    "    z = my_softplus(x)\n",
    "\n",
    "z, tape.gradient(z, [x])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **CUSTOM TRAINING LOOPS:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "l2_reg = tf.keras.regularizers.l2(0.05)\n",
    "model = tf.keras.models.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(\n",
    "            30,\n",
    "            activation=\"relu\",\n",
    "            kernel_initializer=\"he_normal\",\n",
    "            kernel_regularizer=l2_reg,\n",
    "        ),\n",
    "        tf.keras.layers.Dense(1, kernel_regularizer=l2_reg),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(X, y, batch_size=32):\n",
    "    idx = np.random.randint(len(X), size=batch_size)\n",
    "    return X[idx], y[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_status_bar(step, total, loss, metrics=None):\n",
    "    metrics = \" - \".join(\n",
    "        [f\"{m.name}: {m.result():.4f}\" for m in [loss] + (metrics or [])]\n",
    "    )\n",
    "    end = \"\" if step < total else \"\\n\"\n",
    "    print(f\"\\r{step}/{total} - \" + metrics, end=end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "n_epochs = 5\n",
    "batch_size = 32\n",
    "n_steps = len(X_train) // batch_size\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "loss_fn = tf.keras.losses.mean_squared_error\n",
    "mean_loss = tf.keras.metrics.Mean()\n",
    "metrics = [tf.keras.metrics.MeanAbsoluteError()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "362/362 - mean: 3.3938 - mean_absolute_error: 0.6417\n",
      "Epoch 2/5\n",
      "362/362 - mean: 1.7850 - mean_absolute_error: 0.5130\n",
      "Epoch 3/5\n",
      "362/362 - mean: 1.1449 - mean_absolute_error: 0.4885\n",
      "Epoch 4/5\n",
      "362/362 - mean: 0.8681 - mean_absolute_error: 0.4905\n",
      "Epoch 5/5\n",
      "362/362 - mean: 0.7393 - mean_absolute_error: 0.4966\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "    print(f\"Epoch {epoch}/{n_epochs}\")\n",
    "    for step in range(1, n_steps + 1):\n",
    "        X_batch, y_batch = random_batch(X_train_scaled, y_train)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X_batch, training=True)\n",
    "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "            loss = tf.add_n([main_loss] + model.losses)\n",
    "\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "        # extra code - if your model has variable constraints\n",
    "        for variable in model.variables:\n",
    "            if variable.constraint:\n",
    "                variable.assign(variable.constraint(variable))\n",
    "\n",
    "        mean_loss(loss)\n",
    "        for metric in metrics:\n",
    "            metric(y_batch, y_pred)\n",
    "\n",
    "        print_status_bar(step, n_steps, mean_loss, metrics)\n",
    "\n",
    "    for metric in [mean_loss] + metrics:\n",
    "        metric.reset_states()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02094411849975586,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "All epochs",
       "rate": null,
       "total": 5,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "507f270b503c43e79964ba68677066b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "All epochs:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01595616340637207,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Epoch 1/5",
       "rate": null,
       "total": 362,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a50ef8557d2e4a9c879e6812c0fbf27f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/5:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.013997077941894531,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Epoch 2/5",
       "rate": null,
       "total": 362,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79f9df5e76614db0a81c20a909fa2667",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/5:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01200556755065918,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Epoch 3/5",
       "rate": null,
       "total": 362,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b5d5b75623f400dbf9a21d2dadce2a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/5:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01396322250366211,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Epoch 4/5",
       "rate": null,
       "total": 362,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4397bf8ea87e4d4cba77a4f37102c79e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/5:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012997865676879883,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Epoch 5/5",
       "rate": null,
       "total": 362,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d199f8c4d3c44eebbeacab8c66ed8917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/5:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# extra code – shows how to use the tqdm package to display nice progress bars\n",
    "\n",
    "from tqdm.notebook import trange\n",
    "from collections import OrderedDict\n",
    "\n",
    "with trange(1, n_epochs + 1, desc=\"All epochs\") as epochs:\n",
    "    for epoch in epochs:\n",
    "        with trange(1, n_steps + 1, desc=f\"Epoch {epoch}/{n_epochs}\") as steps:\n",
    "            for step in steps:\n",
    "                X_batch, y_batch = random_batch(X_train_scaled, y_train)\n",
    "                \n",
    "                with tf.GradientTape() as tape:\n",
    "                    y_pred = model(X_batch)\n",
    "                    main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "                    loss = tf.add_n([main_loss] + model.losses)\n",
    "\n",
    "                gradients = tape.gradient(loss, model.trainable_variables)\n",
    "                optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "                for variable in model.variables:\n",
    "                    if variable.constraint is not None:\n",
    "                        variable.assign(variable.constraint(variable))\n",
    "\n",
    "                status = OrderedDict()\n",
    "                mean_loss(loss)\n",
    "                status[\"loss\"] = mean_loss.result().numpy()\n",
    "                for metric in metrics:\n",
    "                    metric(y_batch, y_pred)\n",
    "                    status[metric.name] = metric.result().numpy()\n",
    "\n",
    "                steps.set_postfix(status)\n",
    "\n",
    "        for metric in [mean_loss] + metrics:\n",
    "            metric.reset_states()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **TENSORFLOW FUNCTIONS:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cube(x):\n",
    "    return x ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.polymorphic_function.polymorphic_function.Function at 0x2136bc80820>"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube = tf.function(cube)\n",
    "tf_cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=8>"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def tf_cube(x):\n",
    "    return x ** 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** the rest of the code in this section is in appendix D."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **TF FUNCTIONS AND CONCRETE FUNCTIONS:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ConcreteFunction tf_cube(x) at 0x2136E14F910>"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function = tf_cube.get_concrete_function(tf.constant(2.0))\n",
    "concrete_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function(tf.constant(2.0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **EXPLORING FUNCTIONS DEFINITIONS AND GRAPHS:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.func_graph.FuncGraph at 0x2136cf148e0>"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'pow/y' type=Const>,\n",
       " <tf.Operation 'pow' type=Pow>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ops = concrete_function.graph.get_operations()\n",
    "ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'x:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'pow/y:0' shape=() dtype=float32>]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pow_op = ops[2]\n",
    "list(pow_op.inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'pow:0' shape=() dtype=float32>]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pow_op.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Operation 'x' type=Placeholder>"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function.graph.get_operation_by_name('x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Identity:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function.graph.get_tensor_by_name('Identity:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"__inference_tf_cube_1031829\"\n",
       "input_arg {\n",
       "  name: \"x\"\n",
       "  type: DT_FLOAT\n",
       "}\n",
       "output_arg {\n",
       "  name: \"identity\"\n",
       "  type: DT_FLOAT\n",
       "}"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function.function_def.signature\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **HOW TF FUNCTIONS TRACE PYTHON FUNCTIONS TO EXTRACT THEIR COMPUTATION GRAPHS:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def tf_cube(x):\n",
    "    print(f\"x = {x}\")\n",
    "    return x**3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = Tensor(\"x:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "result = tf_cube(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = 2\n"
     ]
    }
   ],
   "source": [
    "result = tf_cube(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = 3\n"
     ]
    }
   ],
   "source": [
    "result = tf_cube(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = Tensor(\"x:0\", shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "result = tf_cube(tf.constant([[1., 2.]]))  # New shape: trace!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = Tensor(\"x:0\", shape=(2, 2), dtype=float32)\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function tf_cube at 0x000002136BCF7BE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function tf_cube at 0x000002136BCF7BE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "result = tf_cube(tf.constant([[3., 4.], [5., 6.]]))  # New shape: trace!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = tf_cube(tf.constant([[7., 8.], [9., 10.]]))  # Same shape: no trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(input_signature=[tf.TensorSpec([None, 28, 28], tf.float32)])\n",
    "def shrink(images):\n",
    "    print(\"Tracing\", images)  # extra code to show when tracing happens\n",
    "    return images[:, ::2, ::2] # drop half the rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing Tensor(\"images:0\", shape=(None, 28, 28), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "img_batch_1 = tf.random.uniform(shape=[100, 28, 28])\n",
    "img_batch_2 = tf.random.uniform(shape=[50, 28, 28])\n",
    "preprocessed_images = shrink(img_batch_1)  # Works fine, traces the function\n",
    "preprocessed_images = shrink(img_batch_2)  # Works fine, same concrete function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python inputs incompatible with input_signature:\n",
      "  inputs: (\n",
      "    tf.Tensor(\n",
      "[[[0.7413678  0.62854624]\n",
      "  [0.01738465 0.3431449 ]]\n",
      "\n",
      " [[0.51063764 0.3777541 ]\n",
      "  [0.07321596 0.02137029]]], shape=(2, 2, 2), dtype=float32))\n",
      "  input_signature: (\n",
      "    TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name=None)).\n"
     ]
    }
   ],
   "source": [
    "img_batch_3 = tf.random.uniform(shape=[2, 2, 2])\n",
    "try:\n",
    "    preprocessed_images = shrink(img_batch_3)  # ValueError! Incompatible inputs\n",
    "except ValueError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **USE AUTOGRAPH TO CAPTURE CONTROL FLOW:**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A \"static\" `for` loop using `range()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def add_10(x):\n",
    "    for i in range(10):\n",
    "        x += 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=15>"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10(tf.constant(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'add/y' type=Const>,\n",
       " <tf.Operation 'add' type=AddV2>,\n",
       " <tf.Operation 'add_1/y' type=Const>,\n",
       " <tf.Operation 'add_1' type=AddV2>,\n",
       " <tf.Operation 'add_2/y' type=Const>,\n",
       " <tf.Operation 'add_2' type=AddV2>,\n",
       " <tf.Operation 'add_3/y' type=Const>,\n",
       " <tf.Operation 'add_3' type=AddV2>,\n",
       " <tf.Operation 'add_4/y' type=Const>,\n",
       " <tf.Operation 'add_4' type=AddV2>,\n",
       " <tf.Operation 'add_5/y' type=Const>,\n",
       " <tf.Operation 'add_5' type=AddV2>,\n",
       " <tf.Operation 'add_6/y' type=Const>,\n",
       " <tf.Operation 'add_6' type=AddV2>,\n",
       " <tf.Operation 'add_7/y' type=Const>,\n",
       " <tf.Operation 'add_7' type=AddV2>,\n",
       " <tf.Operation 'add_8/y' type=Const>,\n",
       " <tf.Operation 'add_8' type=AddV2>,\n",
       " <tf.Operation 'add_9/y' type=Const>,\n",
       " <tf.Operation 'add_9' type=AddV2>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10.get_concrete_function(tf.constant(5)).graph.get_operations()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A \"dynamic\" loop using `tf.while_loop()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra code – shows how to use tf.while_loop (usually @tf.function is simpler)\n",
    "@tf.function\n",
    "def add_10(x):\n",
    "    condition = lambda i, x: tf.less(i, 10)\n",
    "    body = lambda i, x: (tf.add(i, 1), tf.add(x, 1))\n",
    "    final_i, final_x = tf.while_loop(condition, body, [tf.constant(0), x])\n",
    "    return final_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Programy\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\static_analysis\\liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Programy\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\static_analysis\\liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=15>"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10(tf.constant(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'Const' type=Const>,\n",
       " <tf.Operation 'while/maximum_iterations' type=Const>,\n",
       " <tf.Operation 'while/loop_counter' type=Const>,\n",
       " <tf.Operation 'while' type=StatelessWhile>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10.get_concrete_function(tf.constant(5)).graph.get_operations()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A \"dynamic\" `for` loop using `tf.range()` (captured by autograph):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def add_10(x):\n",
    "    for i in tf.range(10):\n",
    "        x = x + 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'range/start' type=Const>,\n",
       " <tf.Operation 'range/limit' type=Const>,\n",
       " <tf.Operation 'range/delta' type=Const>,\n",
       " <tf.Operation 'range' type=Range>,\n",
       " <tf.Operation 'sub' type=Sub>,\n",
       " <tf.Operation 'floordiv' type=FloorDiv>,\n",
       " <tf.Operation 'mod' type=FloorMod>,\n",
       " <tf.Operation 'zeros_like' type=Const>,\n",
       " <tf.Operation 'NotEqual' type=NotEqual>,\n",
       " <tf.Operation 'Cast' type=Cast>,\n",
       " <tf.Operation 'add' type=AddV2>,\n",
       " <tf.Operation 'zeros_like_1' type=Const>,\n",
       " <tf.Operation 'Maximum' type=Maximum>,\n",
       " <tf.Operation 'while/maximum_iterations' type=Const>,\n",
       " <tf.Operation 'while/loop_counter' type=Const>,\n",
       " <tf.Operation 'while' type=StatelessWhile>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10.get_concrete_function(tf.constant(0)).graph.get_operations()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **HANDLING VARIABLES AND OTHER RESOURCES IN TH FUNCTIONS:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=2>"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = tf.Variable(0)\n",
    "\n",
    "@tf.function\n",
    "def increment(counter, c=1):\n",
    "    return counter.assign_add(c)\n",
    "\n",
    "increment(counter)  # counter is now equal to 1\n",
    "increment(counter)  # counter is now equal to 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"counter\"\n",
       "type: DT_RESOURCE"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_def = increment.get_concrete_function(counter).function_def\n",
    "function_def.signature.input_arg[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = tf.Variable(0)\n",
    "\n",
    "@tf.function\n",
    "def increment(c=1):\n",
    "    return counter.assign_add(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=2>"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "increment()\n",
    "increment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"assignaddvariableop_resource\"\n",
       "type: DT_RESOURCE"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_def = increment.get_concrete_function().function_def\n",
    "function_def.signature.input_arg[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Counter:\n",
    "    def __init__(self):\n",
    "        self.counter = tf.Variable(0)\n",
    "\n",
    "    @tf.function\n",
    "    def increment(self, c=1):\n",
    "        return self.counter.assign_add(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=2>"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Counter()\n",
    "c.increment()\n",
    "c.increment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def tf__add(x):\n",
      "    with ag__.FunctionScope('add_10', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
      "        do_return = False\n",
      "        retval_ = ag__.UndefinedReturnValue()\n",
      "\n",
      "        def get_state():\n",
      "            return (x,)\n",
      "\n",
      "        def set_state(vars_):\n",
      "            nonlocal x\n",
      "            (x,) = vars_\n",
      "\n",
      "        def loop_body(itr):\n",
      "            nonlocal x\n",
      "            i = itr\n",
      "            x = ag__.ld(x)\n",
      "            x += 1\n",
      "        i = ag__.Undefined('i')\n",
      "        ag__.for_stmt(ag__.converted_call(ag__.ld(tf).range, (10,), None, fscope), None, loop_body, get_state, set_state, ('x',), {'iterate_names': 'i'})\n",
      "        try:\n",
      "            do_return = True\n",
      "            retval_ = ag__.ld(x)\n",
      "        except:\n",
      "            do_return = False\n",
      "            raise\n",
      "        return fscope.ret(retval_, do_return)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def add_10(x):\n",
    "    for i in tf.range(10):\n",
    "        x += 1\n",
    "    return x\n",
    "\n",
    "print(tf.autograph.to_code(add_10.python_function))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra code – shows how to display the autograph code with syntax highlighting\n",
    "def display_tf_code(func):\n",
    "    from IPython.display import display, Markdown\n",
    "    if hasattr(func, \"python_function\"):\n",
    "        func = func.python_function\n",
    "    code = tf.autograph.to_code(func)\n",
    "    display(Markdown(f'```python\\n{code}\\n```'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "def tf__add(x):\n",
       "    with ag__.FunctionScope('add_10', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
       "        do_return = False\n",
       "        retval_ = ag__.UndefinedReturnValue()\n",
       "\n",
       "        def get_state():\n",
       "            return (x,)\n",
       "\n",
       "        def set_state(vars_):\n",
       "            nonlocal x\n",
       "            (x,) = vars_\n",
       "\n",
       "        def loop_body(itr):\n",
       "            nonlocal x\n",
       "            i = itr\n",
       "            x = ag__.ld(x)\n",
       "            x += 1\n",
       "        i = ag__.Undefined('i')\n",
       "        ag__.for_stmt(ag__.converted_call(ag__.ld(tf).range, (10,), None, fscope), None, loop_body, get_state, set_state, ('x',), {'iterate_names': 'i'})\n",
       "        try:\n",
       "            do_return = True\n",
       "            retval_ = ag__.ld(x)\n",
       "        except:\n",
       "            do_return = False\n",
       "            raise\n",
       "        return fscope.ret(retval_, do_return)\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_tf_code(add_10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **USING TF FUNCTIONS WITH TF.KERAS (OR NOT):**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, tf.keras will automatically convert your custom code into TF Functions, no need to use\n",
    "`tf.function()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom loss function\n",
    "def my_mse(y_true, y_pred):\n",
    "    print(\"Tracing loss my_mse()\")\n",
    "    return tf.reduce_mean(tf.square(y_pred - y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom metric function\n",
    "def my_mae(y_true, y_pred):\n",
    "    print(\"Tracing metric my_mae()\")\n",
    "    return tf.reduce_mean(tf.abs(y_pred - y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom layer\n",
    "class MyDense(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(\n",
    "            name=\"kernel\",\n",
    "            shape=(input_shape[1], self.units),\n",
    "            initializer=\"uniform\",\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.biases = self.add_weight(\n",
    "            name=\"bias\",\n",
    "            shape=(self.units,),\n",
    "            initializer=\"zeros\",\n",
    "            trainable=True,\n",
    "        )\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, X):\n",
    "        print(\"Tracing MyDense.call()\")\n",
    "        return self.activation(X @ self.kernel + self.biases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = MyDense(30, activation=\"relu\")\n",
    "        self.hidden2 = MyDense(30, activation=\"relu\")\n",
    "        self.output_ = MyDense(1)\n",
    "\n",
    "    def call(self, input):\n",
    "        print(\"Tracing MyModel.call()\")\n",
    "        hidden1 = self.hidden1(input)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = tf.keras.layers.concatenate([input, hidden2])\n",
    "        output = self.output_(concat)\n",
    "        return output\n",
    "\n",
    "\n",
    "model = MyModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=my_mse, optimizer=\"nadam\", metrics=[my_mae])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "349/363 [===========================>..] - ETA: 0s - loss: 1.3753 - my_mae: 0.8014Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "363/363 [==============================] - 2s 3ms/step - loss: 1.3436 - my_mae: 0.7899 - val_loss: 0.4403 - val_my_mae: 0.4699\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4378 - my_mae: 0.4751 - val_loss: 0.7764 - val_my_mae: 0.4741\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.4207 - my_mae: 0.4704\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.42070311307907104, 0.47036224603652954]"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2, validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can turn this off by creating the model with `dynamic=True` (or calling `super().__init__(dynamic=True, **kwargs)` in the model's constructor):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "model = MyModel(dynamic=True)\n",
    "model.compile(loss=my_mse, optimizer=\"nadam\", metrics=[my_mae])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the custom code will be called at each iteration. Let's fit, validate and evaluate with tiny datasets to avoid getting too much output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.528679847717285, 2.0647993087768555]"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled[:64],\n",
    "    y_train[:64],\n",
    "    epochs=1,\n",
    "    validation_data=(X_valid_scaled[:64], y_valid[:64]),\n",
    "    verbose=0,\n",
    ")\n",
    "model.evaluate(X_test_scaled[:64], y_test[:64], verbose=0)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can compile a model with `run_eagerly=True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.596070289611816, 2.0684423446655273]"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "model = MyModel()\n",
    "model.compile(loss=my_mse, optimizer=\"nadam\", metrics=[my_mae], run_eagerly=True)\n",
    "model.fit(\n",
    "    X_train_scaled[:64],\n",
    "    y_train[:64],\n",
    "    epochs=1,\n",
    "    validation_data=(X_valid_scaled[:64], y_valid[:64]),\n",
    "    verbose=0,\n",
    ")\n",
    "model.evaluate(X_test_scaled[:64], y_test[:64], verbose=0)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **EXTRA MATERIAL - CUSTOM OPTIMIZERS:**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining custom optimizers is not very common, but in case you are one of the happy few who gets to write one, here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMomentumOptimizer(tf.keras.optimizers.Optimizer):\n",
    "    def __init__(\n",
    "        self, learning_rate=0.001, momentum=0.9, name=\"MyMomentumOptimizer\", **kwargs\n",
    "    ):\n",
    "        \"\"\"Call super().__init__() and use _set_hyper() to store hyperparameters\"\"\"\n",
    "        super().__init__(name, **kwargs)\n",
    "        self._set_hyper(\n",
    "            \"learning_rate\", kwargs.get(\"lr\", learning_rate)\n",
    "        )  # handle lr=learning_rate\n",
    "        self._set_hyper(\"decay\", self._initial_decay)  #\n",
    "        self._set_hyper(\"momentum\", momentum)\n",
    "\n",
    "    def _create_slots(self, var_list):\n",
    "        \"\"\"For each model variable, create the optimizer variable associated with it.\n",
    "        TensorFlow calls these optimizer variables \"slots\".\n",
    "        For momentum optimization, we need one momentum slot per model variable.\n",
    "        \"\"\"\n",
    "        for var in var_list:\n",
    "            self.add_slot(var, \"momentum\")\n",
    "\n",
    "    @tf.function\n",
    "    def _resource_apply_dense(self, grad, var):\n",
    "        \"\"\"Update the slots and perform one optimization step for one model variable\"\"\"\n",
    "        var_dtype = var.dtype.base_dtype\n",
    "        lr_t = self._decayed_lr(var_dtype)  # handle learning rate decay\n",
    "        momentum_var = self.get_slot(var, \"momentum\")\n",
    "        momentum_hyper = self._get_hyper(\"momentum\", var_dtype)\n",
    "        momentum_var.assign(\n",
    "            momentum_var * momentum_hyper - (1.0 - momentum_hyper) * grad\n",
    "        )\n",
    "        var.assign_add(momentum_var * lr_t)\n",
    "\n",
    "    def _resource_apply_sparse(self, grad, var):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {\n",
    "            **base_config,\n",
    "            \"learning_rate\": self._serialize_hyperparameter(\"learning_rate\"),\n",
    "            \"decay\": self._serialize_hyperparameter(\"decay\"),\n",
    "            \"momentum\": self._serialize_hyperparameter(\"momentum\"),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "model = tf.keras.Sequential([tf.keras.layers.Dense(1, input_shape=[8])])\n",
    "model.compile(loss=\"mse\", optimizer=MyMomentumOptimizer())\n",
    "model.fit(X_train_scaled, y_train, epochs=5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
