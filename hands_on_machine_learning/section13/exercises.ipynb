{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ![TensorFlow](https://img.shields.io/badge/TensorFlow-%23FF6F00.svg?style=for-the-badge&logo=TensorFlow&logoColor=white) **LOADING AND PREPROCESSING DATA WITH TENSORFLOW - EXERCISES**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **SETUP:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../initial_settings.py\n",
    "\"\"\"\n",
    "Initial settings for data analysis and machine learning.\n",
    "Use this with: %load ../initial_settings.py\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "from packaging import version\n",
    "\n",
    "# This notebook requires Python 3.7 or above and Scikit-Learn 1.0.1 or above.\n",
    "assert sys.version_info >= (3, 7)\n",
    "assert version.parse(sklearn.__version__) >= version.parse(\"1.0.1\")\n",
    "\n",
    "# And TensorFlow 2.8 or above.\n",
    "assert version.parse(tf.__version__) >= version.parse(\"2.8.0\")\n",
    "\n",
    "# Graphviz source.\n",
    "os.environ[\"PATH\"] += os.pathsep + \"C:/Programy/Graphviz/bin/\"\n",
    "\n",
    "# Default settings for matplotlib.\n",
    "DARK_BLUE = \"#03002e\"\n",
    "LIGHT_GRAY = \"#8f8f99\"\n",
    "\n",
    "plt.rc(\"font\", size=14)\n",
    "plt.rc(\"legend\", fontsize=14)\n",
    "plt.rc(\"text\", color=DARK_BLUE)\n",
    "\n",
    "plt.rc(\"axes\", labelsize=14)\n",
    "plt.rc(\"axes\", titlesize=14)\n",
    "plt.rc(\"axes\", labelpad=10)\n",
    "plt.rc(\"axes\", labelcolor=DARK_BLUE)\n",
    "plt.rc(\"axes\", grid=True)\n",
    "\n",
    "plt.rc(\"xtick\", labelsize=12, color=DARK_BLUE)\n",
    "plt.rc(\"ytick\", labelsize=12, color=DARK_BLUE)\n",
    "plt.rc(\"xtick.major\", pad=10)\n",
    "plt.rc(\"ytick.major\", pad=10)\n",
    "\n",
    "plt.rc(\"grid\", color=LIGHT_GRAY)\n",
    "plt.rc(\"grid\", linestyle=\"dashed\")\n",
    "plt.rc(\"grid\", linewidth=0.5)\n",
    "plt.rc(\"grid\", alpha=0.5)\n",
    "\n",
    "# Create a directory for matplotlib images.\n",
    "IMAGES_PATH = Path(\"images\")\n",
    "IMAGES_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def save_fig(\n",
    "    fig_id, tight_layout=True, fig_extension=\"png\", resolution=300, facecolor=\"w\"\n",
    "):\n",
    "    path = IMAGES_PATH / f\"{fig_id}.{fig_extension}\"\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution, facecolor=facecolor)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **EXERCISE 01:**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a.\n",
    "_Exercise: Load the Fashion MNIST dataset (introduced in Chapter 10); split it into a training set, a validation set, and a test set; shuffle the training set; and save each dataset to multiple TFRecord files. Each record should be a serialized `Example` protobuf with two features: the serialized image (use `tf.io.serialize_tensor()` to serialize each image), and the label. Note: for large images, you could use `tf.io.encode_jpeg()` instead. This would save a lot of space, but it would lose a bit of image quality._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist.load_data()\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "train_set = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "train_set = train_set.shuffle(len(X_train), seed=42)\n",
    "\n",
    "valid_set = tf.data.Dataset.from_tensor_slices((X_valid, y_valid))\n",
    "test_set = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.train import Example, Features, Feature, BytesList, Int64List\n",
    "\n",
    "\n",
    "def create_example(image, label):\n",
    "    image_data = tf.io.serialize_tensor(image)\n",
    "    # image_data = tf.io.encode_jpeg(image[..., np.newaxis])\n",
    "    return Example(\n",
    "        features=Features(\n",
    "            feature={\n",
    "                \"image\": Feature(bytes_list=BytesList(value=[image_data.numpy()])),\n",
    "                \"label\": Feature(int64_list=Int64List(value=[label])),\n",
    "            }\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features {\n",
      "  feature {\n",
      "    key: \"image\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"\\010\\004\\022\\010\\022\\002\\010\\034\\022\\002\\010\\034\\\"\\220\\006\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\001\\000\\000\\rI\\000\\000\\001\\004\\000\\000\\000\\000\\001\\001\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\003\\000$\\210\\177>6\\000\\000\\000\\001\\003\\004\\000\\000\\003\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\006\\000f\\314\\260\\206\\220{\\027\\000\\000\\000\\000\\014\\n\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\233\\354\\317\\262k\\234\\241m@\\027M\\202H\\017\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\001\\000E\\317\\337\\332\\330\\330\\243\\177yz\\222\\215X\\254B\\000\\000\\000\\000\\000\\000\\000\\000\\000\\001\\001\\001\\000\\310\\350\\350\\351\\345\\337\\337\\327\\325\\244\\177{\\304\\345\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\267\\341\\330\\337\\344\\353\\343\\340\\336\\340\\335\\337\\365\\255\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\301\\344\\332\\325\\306\\264\\324\\322\\323\\325\\337\\334\\363\\312\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\001\\003\\000\\014\\333\\334\\324\\332\\300\\251\\343\\320\\332\\340\\324\\342\\305\\3214\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\006\\000c\\364\\336\\334\\332\\313\\306\\335\\327\\325\\336\\334\\365w\\2478\\000\\000\\000\\000\\000\\000\\000\\000\\000\\004\\000\\0007\\354\\344\\346\\344\\360\\350\\325\\332\\337\\352\\331\\331\\321\\\\\\000\\000\\000\\001\\004\\006\\007\\002\\000\\000\\000\\000\\000\\355\\342\\331\\337\\336\\333\\336\\335\\330\\337\\345\\327\\332\\377M\\000\\000\\003\\000\\000\\000\\000\\000\\000\\000>\\221\\314\\344\\317\\325\\335\\332\\320\\323\\332\\340\\337\\333\\327\\340\\364\\237\\000\\000\\000\\000\\000\\022,Rk\\275\\344\\334\\336\\331\\342\\310\\315\\323\\346\\340\\352\\260\\274\\372\\370\\351\\356\\327\\000\\0009\\273\\320\\340\\335\\340\\320\\314\\326\\320\\321\\310\\237\\365\\301\\316\\337\\377\\377\\335\\352\\335\\323\\334\\350\\366\\000\\003\\312\\344\\340\\335\\323\\323\\326\\315\\315\\315\\334\\360P\\226\\377\\345\\335\\274\\232\\277\\322\\314\\321\\336\\344\\341\\000b\\351\\306\\322\\336\\345\\345\\352\\371\\334\\302\\327\\331\\361AIju\\250\\333\\335\\327\\331\\337\\337\\340\\345\\035K\\314\\324\\314\\301\\315\\323\\341\\330\\271\\305\\316\\306\\325\\360\\303\\343\\365\\357\\337\\332\\324\\321\\336\\334\\335\\346C0\\313\\267\\302\\325\\305\\271\\276\\302\\300\\312\\326\\333\\335\\334\\354\\341\\330\\307\\316\\272\\265\\261\\254\\265\\315\\316s\\000z\\333\\301\\263\\253\\267\\304\\314\\322\\325\\317\\323\\322\\310\\304\\302\\277\\303\\277\\306\\300\\260\\234\\247\\261\\322\\\\\\000\\000J\\275\\324\\277\\257\\254\\257\\265\\271\\274\\275\\274\\301\\306\\314\\321\\322\\322\\323\\274\\274\\302\\300\\330\\252\\000\\002\\000\\000\\000B\\310\\336\\355\\357\\362\\366\\363\\364\\335\\334\\301\\277\\263\\266\\266\\265\\260\\246\\250c:\\000\\000\\000\\000\\000\\000\\000\\000\\000(=,H)#\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"label\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 9\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for image, label in valid_set.take(1):\n",
    "    print(create_example(image, label))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function saves a given dataset to a set of TFRecord files. The examples are written to the files in a round-robin fashion. To do this, we enumerate all the examples using the `dataset.enumerate()` method, and we compute `index % n_shards` to decide which file to write to. We use the standard `contextlib.ExitStack` class to make sure that all writers are properly closed whether or not an I/O error occurs while writing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import ExitStack\n",
    "\n",
    "\n",
    "def write_tfrecords(name, dataset, n_shards=10):\n",
    "    path_pattern = \"{}.tfrecord-{:05d}-of-{:05d}\"\n",
    "    paths = [path_pattern.format(name, index, n_shards) for index in range(n_shards)]\n",
    "\n",
    "    with ExitStack() as stack:\n",
    "        writers = [stack.enter_context(tf.io.TFRecordWriter(path)) for path in paths]\n",
    "        for index, (image, label) in dataset.enumerate():\n",
    "            shard = index % n_shards\n",
    "            example = create_example(image, label)\n",
    "            writers[shard].write(example.SerializeToString())\n",
    "\n",
    "    return paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filepaths = write_tfrecords(\"data/mnist/my_fashion_mnist.train\", train_set)\n",
    "valid_filepaths = write_tfrecords(\"data/mnist/my_fashion_mnist.valid\", valid_set)\n",
    "test_filepaths = write_tfrecords(\"data/mnist/my_fashion_mnist.test\", test_set)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b.\n",
    "_Exercise: Then use tf.data to create an efficient dataset for each set. Finally, use a Keras model to train these datasets, including a preprocessing layer to standardize each input feature. Try to make the input pipeline as efficient as possible, using TensorBoard to visualize profiling data._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(tfrecord):\n",
    "    feature_descriptions = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string, default_value=\"\"),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64, default_value=-1),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(tfrecord, feature_descriptions)\n",
    "    image = tf.io.parse_tensor(example[\"image\"], out_type=tf.uint8)\n",
    "    # image = tf.io.decode_jpeg(example[\"image\"])\n",
    "    image = tf.reshape(image, shape=[28, 28])\n",
    "    return image, example[\"label\"]\n",
    "\n",
    "\n",
    "def mnist_dataset(\n",
    "    filepaths,\n",
    "    n_read_threads=5,\n",
    "    shuffle_buffer_size=None,\n",
    "    n_parse_threads=5,\n",
    "    batch_size=32,\n",
    "    cache=True,\n",
    "):\n",
    "    dataset = tf.data.TFRecordDataset(filepaths, num_parallel_reads=n_read_threads)\n",
    "    if cache:\n",
    "        dataset = dataset.cache()\n",
    "    if shuffle_buffer_size:\n",
    "        dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset.prefetch(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = mnist_dataset(train_filepaths, shuffle_buffer_size=60000)\n",
    "valid_set = mnist_dataset(valid_filepaths)\n",
    "test_set = mnist_dataset(test_filepaths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for X, y in train_set.take(1):\n",
    "    for i in range(5):\n",
    "        plt.subplot(1, 5, i + 1)\n",
    "        plt.imshow(X[i].numpy(), cmap=\"binary\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(str(y[i].numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "sample_image_batches = train_set.take(100).map(lambda image, label: image)\n",
    "sample_images = np.concatenate(\n",
    "    list(sample_image_batches.as_numpy_iterator()), axis=0\n",
    ").astype(np.float32)\n",
    "\n",
    "standarization = tf.keras.layers.Normalization(input_shape=[28, 28])\n",
    "standarization.adapt(sample_images)\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        standarization,\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4442 - accuracy: 0.8405 - val_loss: 0.3686 - val_accuracy: 0.8636\n",
      "Epoch 2/5\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3364 - accuracy: 0.8769 - val_loss: 0.3499 - val_accuracy: 0.8714\n",
      "Epoch 3/5\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2977 - accuracy: 0.8900 - val_loss: 0.3287 - val_accuracy: 0.8850\n",
      "Epoch 4/5\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2721 - accuracy: 0.8981 - val_loss: 0.3392 - val_accuracy: 0.8826\n",
      "Epoch 5/5\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2537 - accuracy: 0.9074 - val_loss: 0.3345 - val_accuracy: 0.8860\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x147b51c7e50>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from time import strftime\n",
    "\n",
    "logs = Path() / \"logs\" / strftime(\"run_%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=logs, histogram_freq=1, profile_batch=10\n",
    ")\n",
    "\n",
    "model.fit(train_set, epochs=5, validation_data=valid_set, callbacks=[tensorboard_cb])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **EXERCISE 02:**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Exercise: In this exercise you will download a dataset, split it, create a `tf.data.Dataset` to load it and preprocess it efficiently, then build and train a binary classification model containing an `Embedding` layer._\n",
    "\n",
    "### a.\n",
    "_Exercise: Download the [Large Movie Review Dataset](https://homl.info/imdb), which contains 50,000 movies reviews from the [Internet Movie Database](https://imdb.com/). The data is organized in two directories, `train` and `test`, each containing a `pos` subdirectory with 12,500 positive reviews and a `neg` subdirectory with 12,500 negative reviews. Each review is stored in a separate text file. There are other files and folders (including preprocessed bag-of-words), but we will ignore them in this exercise._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('datasets/aclImdb')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = \"https://ai.stanford.edu/~amaas/data/sentiment/\"\n",
    "filename = \"aclImdb_v1.tar.gz\"\n",
    "filepath = tf.keras.utils.get_file(\n",
    "    filename, root + filename, extract=True, cache_dir=\".\"\n",
    ")\n",
    "path = Path(filepath).with_name(\"aclImdb\")\n",
    "path\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a `tree()` function to view the structure of the `aclImdb` directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree(path, level=0, indent=4, max_files=3):\n",
    "    if level == 0:\n",
    "        print(f\"{path}/\".replace(\"\\\\\", \"/\"))\n",
    "        level += 1\n",
    "\n",
    "    sub_paths = sorted(path.iterdir())\n",
    "    sub_dirs = [sub_path for sub_path in sub_paths if sub_path.is_dir()]\n",
    "    filepaths = [sub_path for sub_path in sub_paths if not sub_path in sub_dirs]\n",
    "\n",
    "    indent_str = \" \" * indent * level\n",
    "\n",
    "    for sub_dir in sub_dirs:\n",
    "        print(f\"{indent_str}{sub_dir.name}/\")\n",
    "        tree(sub_dir, level + 1, indent)\n",
    "\n",
    "    for filepath in filepaths[:max_files]:\n",
    "        print(f\"{indent_str}{filepath.name}\")\n",
    "\n",
    "    if len(filepaths) > max_files:\n",
    "        print(f\"{indent_str}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/aclImdb/\n",
      "    test/\n",
      "        neg/\n",
      "            0_2.txt\n",
      "            10000_4.txt\n",
      "            10001_1.txt\n",
      "            ...\n",
      "        pos/\n",
      "            0_10.txt\n",
      "            10000_7.txt\n",
      "            10001_9.txt\n",
      "            ...\n",
      "        labeledBow.feat\n",
      "        urls_neg.txt\n",
      "        urls_pos.txt\n",
      "    train/\n",
      "        neg/\n",
      "            0_3.txt\n",
      "            10000_4.txt\n",
      "            10001_4.txt\n",
      "            ...\n",
      "        pos/\n",
      "            0_9.txt\n",
      "            10000_8.txt\n",
      "            10001_10.txt\n",
      "            ...\n",
      "        unsup/\n",
      "            0_0.txt\n",
      "            10000_0.txt\n",
      "            10001_0.txt\n",
      "            ...\n",
      "        labeledBow.feat\n",
      "        unsupBow.feat\n",
      "        urls_neg.txt\n",
      "        ...\n",
      "    imdb.vocab\n",
      "    imdbEr.txt\n",
      "    README\n"
     ]
    }
   ],
   "source": [
    "tree(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12500, 12500, 12500, 12500)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def review_paths(dirpath):\n",
    "    return [str(path) for path in dirpath.glob(\"*.txt\")]\n",
    "\n",
    "\n",
    "train_pos = review_paths(path / \"train\" / \"pos\")\n",
    "train_neg = review_paths(path / \"train\" / \"neg\")\n",
    "test_valid_pos = review_paths(path / \"test\" / \"pos\")\n",
    "test_valid_neg = review_paths(path / \"test\" / \"neg\")\n",
    "\n",
    "len(train_pos), len(train_neg), len(test_valid_pos), len(test_valid_neg)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b.\n",
    "_Exercise: Split the test set into a validation set (15,000) and a test set (10,000)._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(test_valid_pos)\n",
    "np.random.shuffle(test_valid_neg)\n",
    "\n",
    "test_pos = test_valid_pos[:5000]\n",
    "test_neg = test_valid_neg[:5000]\n",
    "\n",
    "valid_pos = test_valid_pos[5000:]\n",
    "valid_neg = test_valid_neg[5000:]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c.\n",
    "_Exercise: Use tf.data to create an efficient dataset for each set._"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the dataset fits in memory, we can just load all the data using pure Python code and use `tf.data.Dataset.from_tensor_slices()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imdb_dataset(filepaths_positive, filepaths_negative):\n",
    "    reviews, labels = [], []\n",
    "\n",
    "    for filepaths, label in ((filepaths_negative, 0), (filepaths_positive, 1)):\n",
    "        for filepath in filepaths:\n",
    "            with open(filepath, \"r\", encoding=\"utf-8\") as review_file:\n",
    "                reviews.append(review_file.read())\n",
    "            labels.append(label)\n",
    "\n",
    "    return tf.data.Dataset.from_tensor_slices(\n",
    "        (tf.constant(reviews), tf.constant(labels))\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b\"Story of a man who has unnatural feelings for a pig. Starts out with a opening scene that is a terrific example of absurd comedy. A formal orchestra audience is turned into an insane, violent mob by the crazy chantings of it's singers. Unfortunately it stays absurd the WHOLE time with no general narrative eventually making it just too off putting. Even those from the era should be turned off. The cryptic dialogue would make Shakespeare seem easy to a third grader. On a technical level it's better than you might think with some good cinematography by future great Vilmos Zsigmond. Future stars Sally Kirkland and Frederic Forrest can be seen briefly.\", shape=(), dtype=string)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "\n",
      "tf.Tensor(b\"Airport '77 starts as a brand new luxury 747 plane is loaded up with valuable paintings & such belonging to rich businessman Philip Stevens (James Stewart) who is flying them & a bunch of VIP's to his estate in preparation of it being opened to the public as a museum, also on board is Stevens daughter Julie (Kathleen Quinlan) & her son. The luxury jetliner takes off as planned but mid-air the plane is hi-jacked by the co-pilot Chambers (Robert Foxworth) & his two accomplice's Banker (Monte Markham) & Wilson (Michael Pataki) who knock the passengers & crew out with sleeping gas, they plan to steal the valuable cargo & land on a disused plane strip on an isolated island but while making his descent Chambers almost hits an oil rig in the Ocean & loses control of the plane sending it crashing into the sea where it sinks to the bottom right bang in the middle of the Bermuda Triangle. With air in short supply, water leaking in & having flown over 200 miles off course the problems mount for the survivor's as they await help with time fast running out...<br /><br />Also known under the slightly different tile Airport 1977 this second sequel to the smash-hit disaster thriller Airport (1970) was directed by Jerry Jameson & while once again like it's predecessors I can't say Airport '77 is any sort of forgotten classic it is entertaining although not necessarily for the right reasons. Out of the three Airport films I have seen so far I actually liked this one the best, just. It has my favourite plot of the three with a nice mid-air hi-jacking & then the crashing (didn't he see the oil rig?) & sinking of the 747 (maybe the makers were trying to cross the original Airport with another popular disaster flick of the period The Poseidon Adventure (1972)) & submerged is where it stays until the end with a stark dilemma facing those trapped inside, either suffocate when the air runs out or drown as the 747 floods or if any of the doors are opened & it's a decent idea that could have made for a great little disaster flick but bad unsympathetic character's, dull dialogue, lethargic set-pieces & a real lack of danger or suspense or tension means this is a missed opportunity. While the rather sluggish plot keeps one entertained for 108 odd minutes not that much happens after the plane sinks & there's not as much urgency as I thought there should have been. Even when the Navy become involved things don't pick up that much with a few shots of huge ships & helicopters flying about but there's just something lacking here. George Kennedy as the jinxed airline worker Joe Patroni is back but only gets a couple of scenes & barely even says anything preferring to just look worried in the background.<br /><br />The home video & theatrical version of Airport '77 run 108 minutes while the US TV versions add an extra hour of footage including a new opening credits sequence, many more scenes with George Kennedy as Patroni, flashbacks to flesh out character's, longer rescue scenes & the discovery or another couple of dead bodies including the navigator. While I would like to see this extra footage I am not sure I could sit through a near three hour cut of Airport '77. As expected the film has dated badly with horrible fashions & interior design choices, I will say no more other than the toy plane model effects aren't great either. Along with the other two Airport sequels this takes pride of place in the Razzie Award's Hall of Shame although I can think of lots of worse films than this so I reckon that's a little harsh. The action scenes are a little dull unfortunately, the pace is slow & not much excitement or tension is generated which is a shame as I reckon this could have been a pretty good film if made properly.<br /><br />The production values are alright if nothing spectacular. The acting isn't great, two time Oscar winner Jack Lemmon has said since it was a mistake to star in this, one time Oscar winner James Stewart looks old & frail, also one time Oscar winner Lee Grant looks drunk while Sir Christopher Lee is given little to do & there are plenty of other familiar faces to look out for too.<br /><br />Airport '77 is the most disaster orientated of the three Airport films so far & I liked the ideas behind it even if they were a bit silly, the production & bland direction doesn't help though & a film about a sunken plane just shouldn't be this boring or lethargic. Followed by The Concorde ... Airport '79 (1979).\", shape=(), dtype=string)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "\n",
      "tf.Tensor(b\"This film lacked something I couldn't put my finger on at first: charisma on the part of the leading actress. This inevitably translated to lack of chemistry when she shared the screen with her leading man. Even the romantic scenes came across as being merely the actors at play. It could very well have been the director who miscalculated what he needed from the actors. I just don't know.<br /><br />But could it have been the screenplay? Just exactly who was the chef in love with? He seemed more enamored of his culinary skills and restaurant, and ultimately of himself and his youthful exploits, than of anybody or anything else. He never convinced me he was in love with the princess.<br /><br />I was disappointed in this movie. But, don't forget it was nominated for an Oscar, so judge for yourself.\", shape=(), dtype=string)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for X, y in imdb_dataset(train_pos, train_neg).take(3):\n",
    "    print(X)\n",
    "    print(y)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.7 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r1 for X, y in imdb_dataset(train_pos, train_neg).repeat(10): pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But let's pretend the dataset does not fit in memory, just to make things more interesting. Luckily, each review fits on just one line (they use `<br />` to indicate line breaks), so we can read the reviews using a `TextLineDataset`. If they didn't we would have to preprocess the input files (e.g., converting them to TFRecords). For very large datasets, it would make sense to use a tool like Apache Beam for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imdb_dataset(filepaths_positive, filepaths_negative, n_read_threads=5):\n",
    "    dataset_neg = tf.data.TextLineDataset(\n",
    "        filepaths_negative, num_parallel_reads=n_read_threads\n",
    "    )\n",
    "    dataset_neg = dataset_neg.map(lambda review: (review, 0))\n",
    "\n",
    "    dataset_pos = tf.data.TextLineDataset(\n",
    "        filepaths_positive, num_parallel_reads=n_read_threads\n",
    "    )\n",
    "    dataset_pos = dataset_pos.map(lambda review: (review, 1))\n",
    "\n",
    "    return tf.data.Dataset.concatenate(dataset_pos, dataset_neg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r1 for X, y in imdb_dataset(train_pos, train_neg).repeat(10): pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it takes about 33 seconds to go through the dataset 10 times. That's much slower, essentially because the dataset is not cached in RAM, so it must be reloaded at each epoch. If you add `.cache()` just before `.repeat(10)`, you will see that this implementation will be about as fast as the previous one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.5 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r1 for X, y in imdb_dataset(train_pos, train_neg).cache().repeat(10): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_set = (\n",
    "    imdb_dataset(train_pos, train_neg)\n",
    "    .shuffle(25_000, seed=42)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(1)\n",
    ")\n",
    "valid_set = imdb_dataset(valid_pos, valid_neg).batch(batch_size).prefetch(1)\n",
    "test_set = imdb_dataset(test_pos, test_neg).batch(batch_size).prefetch(1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d.\n",
    "_Exercise: Create a binary classification model, using a `TextVectorization` layer to preprocess each review._"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a `TextVectorization` layer and adapt it to the full IMDB training set (if the training set did not fit in RAM, we could just use a smaller sample of the training set by calling `train_set.take(500)`). Let's use TF-IDF for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens = 1000\n",
    "sample_reviews = train_set.map(lambda review, label: review)\n",
    "text_vectorization = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=max_tokens, output_mode=\"tf_idf\"\n",
    ")\n",
    "text_vectorization.adapt(sample_reviews)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good! Now let's take a look at the first 10 words in the vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[UNK]', 'the', 'and', 'a', 'of', 'to', 'is', 'in', 'it', 'i']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vectorization.get_vocabulary()[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the most common words in the reviews."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're ready to train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 8s 8ms/step - loss: 0.4523 - accuracy: 0.8161 - val_loss: 0.3974 - val_accuracy: 0.8373\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 7s 7ms/step - loss: 0.3532 - accuracy: 0.8574 - val_loss: 0.3757 - val_accuracy: 0.8471\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 7s 8ms/step - loss: 0.3100 - accuracy: 0.8729 - val_loss: 0.3696 - val_accuracy: 0.8459\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 7s 7ms/step - loss: 0.2539 - accuracy: 0.8960 - val_loss: 0.3641 - val_accuracy: 0.8535\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 7s 8ms/step - loss: 0.1981 - accuracy: 0.9215 - val_loss: 0.3968 - val_accuracy: 0.8473\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x147d09a4e20>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        text_vectorization,\n",
    "        tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "model.fit(train_set, epochs=5, validation_data=valid_set)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get about 84.2% accuracy on the validation set after just the first epoch, but after that the model makes no significant progress. We will do better in Chapter 16. For now the point is just to perform efficient preprocessing using `tf.data` and Keras preprocessing layers."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e.\n",
    "_Exercise: Add an `Embedding` layer and compute the mean embedding for each review, multiplied by the square root of the number of words (see Chapter 16). This rescaled mean embedding can then be passed to the rest of your model._"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the mean embedding for each review, and multiply it by the square root of the number of words in that review, we will need a little function. For each sentence, this function needs to compute $M \\times \\sqrt N$, where $M$ is the mean of all the word embeddings in the sentence (excluding padding tokens), and $N$ is the number of words in the sentence (also excluding padding tokens). We can rewrite $M$ as $\\dfrac{S}{N}$, where $S$ is the sum of all word embeddings (it does not matter whether or not we include the padding tokens in this sum, since their representation is a zero vector). So the function must return $M \\times \\sqrt N = \\dfrac{S}{N} \\times \\sqrt N = \\dfrac{S}{\\sqrt N \\times \\sqrt N} \\times \\sqrt N= \\dfrac{S}{\\sqrt N}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[3.535534 , 4.9497476, 2.1213205],\n",
       "       [6.       , 0.       , 0.       ]], dtype=float32)>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_mean_embedding(inputs):\n",
    "    not_pad = tf.math.count_nonzero(inputs, axis=-1)\n",
    "    n_words = tf.math.count_nonzero(not_pad, axis=-1, keepdims=True)\n",
    "    sqrt_n_words = tf.math.sqrt(tf.cast(n_words, tf.float32))\n",
    "    return tf.reduce_sum(inputs, axis=1) / sqrt_n_words\n",
    "\n",
    "\n",
    "another_example = tf.constant(\n",
    "    [\n",
    "        [[1.0, 2.0, 3.0], [4.0, 5.0, 0.0], [0.0, 0.0, 0.0]],\n",
    "        [[6.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0]],\n",
    "    ]\n",
    ")\n",
    "compute_mean_embedding(another_example)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that this is correct. The first review contains 2 words (the last token is a zero vector, which represents the `<pad>` token). Let's compute the mean embedding for these 2 words, and multiply the result by the square root of 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[3.535534 , 4.9497476, 2.1213202]], dtype=float32)>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(another_example[0:1, :2], axis=1) * tf.sqrt(2.0)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good! Now let's check the second review, which contains just one word (we ignore the two padding tokens):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[6., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(another_example[1:2, :1], axis=1) * tf.sqrt(1.0)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect. Now we're ready to train our final model. It's the same as before, except we replaced TF-IDF with ordinal encoding (`output_mode=\"int\"`) followed by an `Embedding` layer, followed by a `Lambda` layer that calls the `compute_mean_embedding` layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "embedding_size = 20\n",
    "\n",
    "text_vectorization = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=max_tokens, output_mode=\"int\"\n",
    ")\n",
    "text_vectorization.adapt(sample_reviews)\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        text_vectorization,\n",
    "        tf.keras.layers.Embedding(\n",
    "            input_dim=max_tokens,\n",
    "            output_dim=embedding_size,\n",
    "            mask_zero=True,  # <pad> tokens => zero vectors\n",
    "        ),\n",
    "        tf.keras.layers.Lambda(compute_mean_embedding),\n",
    "        tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f.\n",
    "_Exercise: Train the model and see what accuracy you get. Try to optimize your pipelines to make training as fast as possible._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 12s 13ms/step - loss: 0.4696 - accuracy: 0.7775 - val_loss: 0.3410 - val_accuracy: 0.8568\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 11s 13ms/step - loss: 0.3353 - accuracy: 0.8574 - val_loss: 0.3629 - val_accuracy: 0.8389\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 11s 13ms/step - loss: 0.3179 - accuracy: 0.8631 - val_loss: 0.3146 - val_accuracy: 0.8647\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 10s 12ms/step - loss: 0.3110 - accuracy: 0.8668 - val_loss: 0.3173 - val_accuracy: 0.8621\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 11s 13ms/step - loss: 0.3075 - accuracy: 0.8684 - val_loss: 0.3164 - val_accuracy: 0.8625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x147d0e97400>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "model.fit(train_set, epochs=5, validation_data=valid_set)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is just marginally better using embeddings (but we will do better in Chapter 16). The pipeline looks fast enough (we optimized it earlier)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### g.\n",
    "_Exercise: Use TFDS to load the same dataset more easily: `tfds.load(\"imdb_reviews\")`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\Mateusz\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0...\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01695990562438965,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Dl Completed...",
       "rate": null,
       "total": 0,
       "unit": " url",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8235e4b171314a1bbe762a9e8a6678f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01575493812561035,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Dl Size...",
       "rate": null,
       "total": 0,
       "unit": " MiB",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6034e13230f4bfba46e32454802839d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015955686569213867,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Generating splits...",
       "rate": null,
       "total": 3,
       "unit": " splits",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fce1d6acd10f44c28ee1f152861db00f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/3 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.013961553573608398,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Generating train examples...",
       "rate": null,
       "total": null,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3c59a98c7cf4ed19b940bfc8eedcaed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.013976812362670898,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Shuffling C:\\Users\\Mateusz\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0.incompleteRJVTVP\\imdb_reviews-train.tfrecord*...",
       "rate": null,
       "total": 25000,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3a0bf91d23d4cba9d682052248e3ef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling C:\\Users\\Mateusz\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0.incompleteRJVTVP\\imdb_reviews-tra…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.014928340911865234,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Generating test examples...",
       "rate": null,
       "total": null,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e87275dd62f4709b746ec2077a0eeca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.014960289001464844,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Shuffling C:\\Users\\Mateusz\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0.incompleteRJVTVP\\imdb_reviews-test.tfrecord*...",
       "rate": null,
       "total": 25000,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35fa282e78874682ad34f1c72a52ce39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling C:\\Users\\Mateusz\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0.incompleteRJVTVP\\imdb_reviews-tes…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.018950700759887695,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Generating unsupervised examples...",
       "rate": null,
       "total": null,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d0e064cb2b349358fa9e06ab89fe984",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating unsupervised examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012916803359985352,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Shuffling C:\\Users\\Mateusz\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0.incompleteRJVTVP\\imdb_reviews-unsupervised.tfrecord*...",
       "rate": null,
       "total": 50000,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b675e4d3373648e6a96edc544b30a101",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling C:\\Users\\Mateusz\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0.incompleteRJVTVP\\imdb_reviews-uns…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset imdb_reviews downloaded and prepared to C:\\Users\\Mateusz\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "datasets = tfds.load(name=\"imdb_reviews\")\n",
    "train_set, test_set = datasets[\"train\"], datasets[\"test\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\", shape=(), dtype=string)\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for example in train_set.take(1):\n",
    "    print(example[\"text\"])\n",
    "    print(example[\"label\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
