{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "from collections import defaultdict\n",
    "from copy import copy\n",
    "from itertools import product\n",
    "from functools import reduce\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "# Sub-modules and so on.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from colorama import Fore, Style\n",
    "from IPython.core.display import HTML\n",
    "from IPython.display import display_html\n",
    "from matplotlib.colors import Colormap\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy.cluster.hierarchy import fcluster, linkage\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.stats import gaussian_kde, probplot\n",
    "\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.compose import make_column_selector\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn import set_config\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import Binarizer, OrdinalEncoder\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn.feature_selection import RFE, SelectPercentile, SequentialFeatureSelector\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cluster import AffinityPropagation, KMeans, MeanShift, Birch\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from scipy.stats import randint, expon, reciprocal, uniform\n",
    "\n",
    "ON_KAGGLE = os.getenv(\"KAGGLE_KERNEL_RUN_TYPE\") is not None\n",
    "\n",
    "# Colorama settings.\n",
    "CLR = (Style.BRIGHT + Fore.BLACK) if ON_KAGGLE else (Style.BRIGHT + Fore.WHITE)\n",
    "RED = Style.BRIGHT + Fore.RED\n",
    "BLUE = Style.BRIGHT + Fore.BLUE\n",
    "CYAN = Style.BRIGHT + Fore.CYAN\n",
    "RESET = Style.RESET_ALL\n",
    "\n",
    "# Colors\n",
    "DF_CMAP: Colormap = sns.light_palette(\"#8C92AC\", as_cmap=True)  # type: ignore\n",
    "FONT_COLOR = \"#010D36\"\n",
    "BACKGROUND_COLOR = \"#F6F5F5\"\n",
    "\n",
    "cell_hover = {  # for row hover use <tr> instead of <td>\n",
    "    \"selector\": \"td:hover\",\n",
    "    \"props\": \"background-color: #F6F5F5\",\n",
    "}\n",
    "text_highlight = {\n",
    "    \"selector\": \"td\",\n",
    "    \"props\": \"color: #FF2079; font-weight: bold\",\n",
    "}\n",
    "index_names = {\n",
    "    \"selector\": \".index_name\",\n",
    "    \"props\": \"font-style: italic; background-color: #010D36; color: #F2F2F0;\",\n",
    "}\n",
    "headers = {\n",
    "    \"selector\": \"th:not(.index_name)\",\n",
    "    \"props\": \"font-style: italic; background-color: #010D36; color: #F2F2F0;\",\n",
    "}\n",
    "DF_STYLE = (index_names, headers, text_highlight)\n",
    "\n",
    "MY_RC = {\n",
    "    \"axes.labelcolor\": FONT_COLOR,\n",
    "    \"axes.labelsize\": 10,\n",
    "    \"axes.labelpad\": 15,\n",
    "    \"axes.labelweight\": \"bold\",\n",
    "    \"axes.titlesize\": 14,\n",
    "    \"axes.titleweight\": \"bold\",\n",
    "    \"axes.titlepad\": 15,\n",
    "    \"axes.facecolor\": BACKGROUND_COLOR,\n",
    "    \"xtick.labelsize\": 10,\n",
    "    \"xtick.color\": FONT_COLOR,\n",
    "    \"ytick.labelsize\": 10,\n",
    "    \"ytick.color\": FONT_COLOR,\n",
    "    \"figure.titlesize\": 14,\n",
    "    \"figure.titleweight\": \"bold\",\n",
    "    \"figure.facecolor\": BACKGROUND_COLOR,\n",
    "    \"figure.edgecolor\": BACKGROUND_COLOR,\n",
    "    \"figure.dpi\": 72,  # Locally Seaborn uses 72, meanwhile Kaggle 96.\n",
    "    \"font.size\": 10,\n",
    "    \"font.family\": \"Serif\",\n",
    "    \"text.color\": FONT_COLOR,\n",
    "}\n",
    "sns.set_theme(rc=MY_RC)\n",
    "\n",
    "\n",
    "# Utility functions.\n",
    "def download_dataset_from_kaggle(user, dataset, directory):\n",
    "    command = \"kaggle datasets download -d \"\n",
    "    filepath = directory / (dataset + \".zip\")\n",
    "\n",
    "    if not filepath.is_file():\n",
    "        subprocess.run((command + user + \"/\" + dataset).split())\n",
    "        filepath.parent.mkdir(parents=True, exist_ok=True)\n",
    "        shutil.unpack_archive(dataset + \".zip\", \"data\")\n",
    "        shutil.move(dataset + \".zip\", \"data\")\n",
    "\n",
    "\n",
    "def download_competition_from_kaggle(competition):\n",
    "    command = \"kaggle competitions download -c \"\n",
    "    filepath = Path(\"data/\" + competition + \".zip\")\n",
    "\n",
    "    if not filepath.is_file():\n",
    "        subprocess.run((command + competition).split())\n",
    "        Path(\"data\").mkdir(parents=True, exist_ok=True)\n",
    "        shutil.unpack_archive(competition + \".zip\", \"data\")\n",
    "        shutil.move(competition + \".zip\", \"data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "competition = \"icr-identify-age-related-conditions\"\n",
    "\n",
    "if not ON_KAGGLE:\n",
    "    download_competition_from_kaggle(competition)\n",
    "    train_path = \"data/train.csv\"\n",
    "    test_path = \"data/test.csv\"\n",
    "    greeks_path = \"data/greeks.csv\"\n",
    "else:\n",
    "    train_path = f\"/kaggle/input/{competition}/train.csv\"\n",
    "    test_path = f\"/kaggle/input/{competition}/test.csv\"\n",
    "    greeks_path = f\"/kaggle/input/{competition}/greeks.csv\"\n",
    "\n",
    "train = pd.read_csv(train_path, index_col=\"Id\").rename(columns=str.strip)\n",
    "test = pd.read_csv(test_path, index_col=\"Id\").rename(columns=str.strip)\n",
    "greeks = pd.read_csv(greeks_path, index_col=\"Id\").rename(columns=str.strip)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_descr = (\n",
    "    train.drop(\"Class\", axis=1)\n",
    "    .describe(percentiles=[0.01, 0.05, 0.25, 0.50, 0.75, 0.95, 0.99])\n",
    "    .drop(\"count\")\n",
    "    .T.rename(columns=str.title)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_data = train.select_dtypes(\"number\")\n",
    "numeric_cols = numeric_data.drop(\"Class\", axis=1).columns.tolist()\n",
    "r2_scores = defaultdict(tuple)\n",
    "\n",
    "for feature in numeric_cols:\n",
    "    orig = train[feature].dropna()\n",
    "    _, (*_, R_orig) = probplot(orig, rvalue=True)\n",
    "    _, (*_, R_log) = probplot(np.log(orig), rvalue=True)\n",
    "    _, (*_, R_sqrt) = probplot(np.sqrt(orig), rvalue=True)\n",
    "    _, (*_, R_reci) = probplot(np.reciprocal(orig), rvalue=True)\n",
    "    _, (*_, R_boxcox) = probplot(stats.boxcox(orig)[0], rvalue=True)\n",
    "    _, (*_, R_yeojohn) = probplot(stats.yeojohnson(orig)[0], rvalue=True)\n",
    "    r2_scores[feature] = (\n",
    "        R_orig * R_orig,\n",
    "        R_log * R_log,\n",
    "        R_sqrt * R_sqrt,\n",
    "        R_reci * R_reci,\n",
    "        R_boxcox * R_boxcox,\n",
    "        R_yeojohn * R_yeojohn,\n",
    "    )\n",
    "\n",
    "r2_scores = pd.DataFrame(\n",
    "    r2_scores, index=(\"Original\", \"Log\", \"Sqrt\", \"Reciprocal\", \"BoxCox\", \"YeoJohnson\")\n",
    ").T\n",
    "\n",
    "r2_scores[\"Winner\"] = r2_scores.idxmax(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_transform_cols = r2_scores.query(\"Winner == 'Original'\").index\n",
    "log_transform_cols = r2_scores.query(\"Winner == 'Log'\").index\n",
    "reciprocal_transform_cols = r2_scores.query(\"Winner == 'Reciprocal'\").index\n",
    "boxcox_transform_cols = r2_scores.query(\"Winner == 'BoxCox'\").index\n",
    "yeojohnson_transform_cols = r2_scores.query(\"Winner == 'YeoJohnson'\").index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "semi_constant_mask = np.isclose(numeric_descr[\"Min\"], numeric_descr[\"50%\"])\n",
    "semi_constant_descr = numeric_descr[semi_constant_mask]\n",
    "semi_const_cols_thresholds = semi_constant_descr[\"50%\"].to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "semi_const_cols = semi_const_cols_thresholds.keys()\n",
    "\n",
    "no_transform_cols = no_transform_cols.drop(semi_const_cols, errors=\"ignore\")\n",
    "log_transform_cols = log_transform_cols.drop(semi_const_cols, errors=\"ignore\")\n",
    "reciprocal_transform_cols = reciprocal_transform_cols.drop(semi_const_cols, errors=\"ignore\")\n",
    "boxcox_transform_cols = boxcox_transform_cols.drop(semi_const_cols, errors=\"ignore\")\n",
    "yeojohnson_transform_cols = yeojohnson_transform_cols.drop(semi_const_cols, errors=\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "semi_final_preprocess = make_pipeline(\n",
    "    make_column_transformer(\n",
    "        (\n",
    "            StandardScaler(),\n",
    "            no_transform_cols.to_list(),\n",
    "        ),\n",
    "        (\n",
    "            make_pipeline(\n",
    "                FunctionTransformer(func=np.log, feature_names_out=\"one-to-one\"),\n",
    "                StandardScaler(),\n",
    "            ),\n",
    "            log_transform_cols.to_list(),\n",
    "        ),\n",
    "        (\n",
    "            make_pipeline(\n",
    "                FunctionTransformer(func=np.reciprocal, feature_names_out=\"one-to-one\"),\n",
    "                StandardScaler(),\n",
    "            ),\n",
    "            reciprocal_transform_cols.to_list(),\n",
    "        ),\n",
    "        (\n",
    "            PowerTransformer(method=\"box-cox\", standardize=True),\n",
    "            boxcox_transform_cols.to_list(),\n",
    "        ),\n",
    "        (\n",
    "            PowerTransformer(method=\"yeo-johnson\", standardize=True),\n",
    "            yeojohnson_transform_cols.to_list(),\n",
    "        ),\n",
    "        (\n",
    "            make_pipeline(\n",
    "                SimpleImputer(strategy=\"most_frequent\"),\n",
    "                OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1),\n",
    "            ),\n",
    "            make_column_selector(dtype_include=object),  # type: ignore\n",
    "        ),\n",
    "        *[\n",
    "            (\n",
    "                make_pipeline(\n",
    "                    SimpleImputer(strategy=\"median\"),\n",
    "                    Binarizer(threshold=thresh),\n",
    "                ),\n",
    "                [col],\n",
    "            )\n",
    "            for col, thresh in semi_const_cols_thresholds.items()\n",
    "        ],\n",
    "        remainder=\"drop\",\n",
    "        verbose_feature_names_out=False,\n",
    "    ),\n",
    "    KNNImputer(n_neighbors=10, weights=\"distance\"),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_log_loss(y_true, y_pred, **kwargs):\n",
    "    \"\"\"Competition evaluation metric - negative balanced logarithmic loss.\n",
    "    The overall effect is such that each class is roughly equally\n",
    "    important for the final score.\"\"\"\n",
    "    N0, N1 = np.bincount(y_true)\n",
    "\n",
    "    y0 = np.where(y_true == 0, 1, 0)\n",
    "    y1 = np.where(y_true == 1, 1, 0)\n",
    "\n",
    "    eps = kwargs.get(\"eps\", 1e-15)\n",
    "    y_pred = np.clip(y_pred, eps, 1 - eps)\n",
    "    p0 = np.log(1 - y_pred)\n",
    "    p1 = np.log(y_pred)\n",
    "\n",
    "    return -(1 / N0 * np.sum(y0 * p0) + 1 / N1 * np.sum(y1 * p1)) * 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_downsampling_fraction(y_true):\n",
    "    N0, N1 = np.bincount(y_true)\n",
    "    return 1 - N1 / N0\n",
    "\n",
    "\n",
    "def assert_balanced_learning(y_train, n_samples_tol=1):\n",
    "    N0, N1 = np.bincount(y_train)\n",
    "    assert np.isclose(N0, N1, atol=n_samples_tol)\n",
    "\n",
    "\n",
    "def get_samples_weight(y_true):\n",
    "    N0, N1 = np.bincount(y_true)\n",
    "    y0, y1 = np.unique(y_true)\n",
    "    w0 = (N0 + N1) / N0\n",
    "    w1 = (N0 + N1) / N1\n",
    "    return np.where(y_true == y1, w1, w0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_BAGS = 20\n",
    "N_FOLDS = 10  # Provides relative balance between class 0 in downsampled train and valid subsets.\n",
    "\n",
    "np.random.seed(42)\n",
    "seeds = np.random.randint(0, 19937, size=N_BAGS)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING CELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(\"Class\", axis=1)\n",
    "y = train.Class\n",
    "\n",
    "downsampling_frac = get_downsampling_fraction(y)\n",
    "y_proba = np.zeros_like(y, dtype=np.float64)\n",
    "results = defaultdict(np.float64)\n",
    "classifiers = defaultdict(object)\n",
    "\n",
    "lgbm_params = {\n",
    "    \"max_depth\": 4,\n",
    "    \"num_leaves\": 9,\n",
    "    \"min_child_samples\": 20,\n",
    "    \"n_estimators\": 200,\n",
    "    \"learning_rate\": 0.15,\n",
    "    \"colsample_bytree\": 0.4,\n",
    "    \"reg_alpha\": 1e-2,\n",
    "    \"min_split_gain\": 1e-4,\n",
    "}\n",
    "\n",
    "xgb_params = {\n",
    "    \"max_depth\": 2,\n",
    "    \"n_estimators\": 200,\n",
    "    \"learning_rate\": 0.4,\n",
    "    \"gamma\": 1e-4,\n",
    "    \"min_child_weight\": 0.1,\n",
    "    \"max_delta_step\": 0.35,\n",
    "    \"colsample_bytree\": 0.3,\n",
    "    \"colsample_bylevel\": 0.7,\n",
    "    \"reg_alpha\": 2e-3,\n",
    "}\n",
    "\n",
    "params = np.arange(4, 11, 1)\n",
    "\n",
    "for param in params:\n",
    "    y_proba = np.zeros_like(y, dtype=np.float64)\n",
    "\n",
    "    for bag, seed in enumerate(seeds):\n",
    "        skfold = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=seed)\n",
    "        # ap = AffinityPropagation(damping=0.8, random_state=seed)\n",
    "\n",
    "        for fold, (train_ids, valid_ids) in enumerate(skfold.split(X, y)):\n",
    "            y_train_full = y.iloc[train_ids]\n",
    "            rmv = (\n",
    "                y_train_full[y_train_full == 0]\n",
    "                .sample(frac=downsampling_frac, random_state=seed)\n",
    "                .index.to_numpy()\n",
    "            )\n",
    "            # Skfold returns numbers, but `y` is a series with IDs, so we map them.\n",
    "            rmv = [y.index.get_loc(idx) for idx in rmv]\n",
    "            train_ids = np.setdiff1d(train_ids, rmv)\n",
    "\n",
    "            X_train, y_train = X.iloc[train_ids], y.iloc[train_ids]\n",
    "            X_valid, y_valid = X.iloc[valid_ids], y.iloc[valid_ids]\n",
    "\n",
    "            assert_balanced_learning(y_train)\n",
    "\n",
    "            X_train = semi_final_preprocess.fit_transform(X_train, y_train)\n",
    "            X_valid = semi_final_preprocess.transform(X_valid)\n",
    "\n",
    "            # current_svc = SVC(random_state=seed, probability=True, C=3)\n",
    "            # current_svc.fit(X_train, y_train)\n",
    "\n",
    "            # y_proba[valid_ids] += current_svc.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "            # X_train_ap = ap.fit_predict(X_train)[:, np.newaxis]\n",
    "            # X_valid_ap = ap.predict(X_valid)[:, np.newaxis]\n",
    "\n",
    "            # X_train = np.concatenate((X_train, X_train_ap), axis=1)\n",
    "            # X_valid = np.concatenate((X_valid, X_valid_ap), axis=1)\n",
    "\n",
    "            current_lgbm = LGBMClassifier(\n",
    "                random_state=seed,\n",
    "                max_depth=param,\n",
    "                min_child_samples=4,\n",
    "                num_leaves=64,\n",
    "            )\n",
    "            # current_xgb = XGBClassifier(random_state=seed, **xgb_params)\n",
    "\n",
    "            current_lgbm.fit(X_train, y_train)\n",
    "            # current_xgb.fit(X_train, y_train)\n",
    "\n",
    "            y_proba[valid_ids] += current_lgbm.predict_proba(X_valid)[:, 1]\n",
    "            #     current_lgbm.predict_proba(X_valid)[:, 1]\n",
    "            #     + current_xgb.predict_proba(X_valid)[:, 1]\n",
    "            # )\n",
    "\n",
    "    results[param] = balanced_log_loss(y, y_proba / N_BAGS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4     0.269503\n",
       "5     0.280840\n",
       "6     0.288462\n",
       "10    0.289321\n",
       "9     0.290360\n",
       "7     0.294261\n",
       "8     0.295345\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(results).sort_values()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_proba_rescaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Mateusz\\Documents\\PythonRepository\\kaggle_notebooks\\icr\\submission_notebook.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Mateusz/Documents/PythonRepository/kaggle_notebooks/icr/submission_notebook.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m boost \u001b[39m=\u001b[39m \u001b[39m0.85\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Mateusz/Documents/PythonRepository/kaggle_notebooks/icr/submission_notebook.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m preds \u001b[39m=\u001b[39m y_proba_rescaled\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Mateusz/Documents/PythonRepository/kaggle_notebooks/icr/submission_notebook.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m odds \u001b[39m=\u001b[39m boost \u001b[39m*\u001b[39m preds \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m preds)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Mateusz/Documents/PythonRepository/kaggle_notebooks/icr/submission_notebook.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m preds \u001b[39m=\u001b[39m odds \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m odds)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_proba_rescaled' is not defined"
     ]
    }
   ],
   "source": [
    "boost = 0.85\n",
    "preds = y_proba_rescaled.copy()\n",
    "odds = boost * preds / (1 - preds)\n",
    "preds = odds / (1 + odds)\n",
    "balanced_log_loss(y, preds)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEARNING CELL AND SUBMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Log Loss: -0.22280\n"
     ]
    }
   ],
   "source": [
    "X = train.drop(\"Class\", axis=1)\n",
    "y = train.Class\n",
    "\n",
    "downsampling_frac = get_downsampling_fraction(y)\n",
    "y_proba = np.zeros_like(y, dtype=np.float64)\n",
    "results = defaultdict(np.float64)\n",
    "classifiers = defaultdict(object)\n",
    "\n",
    "lgbm_params = {\n",
    "    \"max_depth\": 4,\n",
    "    \"num_leaves\": 9,\n",
    "    \"min_child_samples\": 20,\n",
    "    \"n_estimators\": 200,\n",
    "    \"learning_rate\": 0.15,\n",
    "    \"colsample_bytree\": 0.4,\n",
    "    \"reg_alpha\": 1e-2,\n",
    "    \"min_split_gain\": 1e-4,\n",
    "}\n",
    "\n",
    "xgb_params = {\n",
    "    \"max_depth\": 2,\n",
    "    \"n_estimators\": 200,\n",
    "    \"learning_rate\": 0.4,\n",
    "    \"min_child_weight\": 0.1,\n",
    "    \"max_delta_step\": 0.35,\n",
    "    \"colsample_bytree\": 0.3,\n",
    "    \"colsample_bylevel\": 0.7,\n",
    "    \"gamma\": 1e-4,\n",
    "    \"reg_alpha\": 2e-3,\n",
    "}\n",
    "\n",
    "for bag, seed in enumerate(seeds):\n",
    "    skfold = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=seed)\n",
    "\n",
    "    for fold, (train_ids, valid_ids) in enumerate(skfold.split(X, y)):\n",
    "        y_train_full = y.iloc[train_ids]\n",
    "        rmv = (\n",
    "            y_train_full[y_train_full == 0]\n",
    "            .sample(frac=downsampling_frac, random_state=seed)\n",
    "            .index.to_numpy()\n",
    "        )\n",
    "        # Skfold returns numbers, but `y` is a series with IDs, so we map them.\n",
    "        rmv = [y.index.get_loc(idx) for idx in rmv]\n",
    "        train_ids = np.setdiff1d(train_ids, rmv)\n",
    "\n",
    "        X_train, y_train = X.iloc[train_ids], y.iloc[train_ids]\n",
    "        X_valid, y_valid = X.iloc[valid_ids], y.iloc[valid_ids]\n",
    "\n",
    "        assert_balanced_learning(y_train)\n",
    "\n",
    "        X_train = semi_final_preprocess.fit_transform(X_train, y_train)\n",
    "        X_valid = semi_final_preprocess.transform(X_valid)\n",
    "\n",
    "        current_lgbm = LGBMClassifier(random_state=seed, **lgbm_params)\n",
    "        current_xgb = XGBClassifier(random_state=seed, **xgb_params)\n",
    "\n",
    "        current_lgbm.fit(X_train, y_train)\n",
    "        current_xgb.fit(X_train, y_train)\n",
    "\n",
    "        y_proba[valid_ids] += 0.5 * (\n",
    "            current_lgbm.predict_proba(X_valid)[:, 1]\n",
    "            + current_xgb.predict_proba(X_valid)[:, 1]\n",
    "        )\n",
    "\n",
    "        classifiers[f\"LGBM Bag: {bag} Fold: {fold}\"] = current_lgbm\n",
    "        classifiers[f\"XGB Bag: {bag} Fold: {fold}\"] = current_xgb\n",
    "\n",
    "y_proba_rescaled = y_proba / N_BAGS\n",
    "print(\"Balanced Log Loss:\", f\"{-balanced_log_loss(y, y_proba / N_BAGS):.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba_frame = pd.DataFrame(\n",
    "    {\n",
    "        \"Sample Integer Index\": np.arange(0, len(y)),\n",
    "        \"Positive Class Probability\": y_proba_rescaled,\n",
    "        \"Class\": y.values.astype(str),\n",
    "    },\n",
    "    index=y.index,\n",
    ")\n",
    "\n",
    "fig = px.scatter(\n",
    "    y_proba_frame.reset_index(),\n",
    "    x=\"Positive Class Probability\",\n",
    "    y=\"Sample Integer Index\",\n",
    "    symbol=\"Class\",\n",
    "    symbol_sequence=[\"diamond\", \"circle\"],\n",
    "    color=\"Class\",\n",
    "    color_discrete_sequence=[\"#010D36\", \"#FF2079\"],\n",
    "    category_orders={\"Class\": (\"0\", \"1\")},\n",
    "    hover_data=\"Id\",\n",
    "    opacity=0.6,\n",
    "    height=540,\n",
    "    width=840,\n",
    "    title=\"Training Dataset - Out of Fold Predictions\",\n",
    ")\n",
    "fig.update_layout(\n",
    "    font_color=FONT_COLOR,\n",
    "    title_font_size=18,\n",
    "    plot_bgcolor=BACKGROUND_COLOR,\n",
    "    paper_bgcolor=BACKGROUND_COLOR,\n",
    "    legend=dict(\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"bottom\",\n",
    "        xanchor=\"right\",\n",
    "        y=1.05,\n",
    "        x=1,\n",
    "        title=\"Class\",\n",
    "        itemsizing=\"constant\",\n",
    "    ),\n",
    "    xaxis_range=[-0.02, 1.02],\n",
    ")\n",
    "fig.update_traces(marker_size=6)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.all(np.isclose(test.select_dtypes(\"number\").sum(), 0)):\n",
    "    test_numeric_cols = test.select_dtypes(\"number\").columns\n",
    "    test[test_numeric_cols] += 1e-9\n",
    "\n",
    "test_ids = test.index\n",
    "\n",
    "X_test = semi_final_preprocess.transform(test)\n",
    "y_test = np.zeros_like(test_ids)\n",
    "\n",
    "for classifier in classifiers.values():\n",
    "    y_test += classifier.predict_proba(X_test)[:, 1]\n",
    "\n",
    "y_test_rescaled = y_test / len(classifiers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_0</th>\n",
       "      <th>class_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00eed32682bb</th>\n",
       "      <td>0.526639</td>\n",
       "      <td>0.473361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>010ebe33f668</th>\n",
       "      <td>0.526639</td>\n",
       "      <td>0.473361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02fa521e1838</th>\n",
       "      <td>0.526639</td>\n",
       "      <td>0.473361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>040e15f562a2</th>\n",
       "      <td>0.526639</td>\n",
       "      <td>0.473361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>046e85c7cc7f</th>\n",
       "      <td>0.526639</td>\n",
       "      <td>0.473361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               class_0   class_1\n",
       "Id                              \n",
       "00eed32682bb  0.526639  0.473361\n",
       "010ebe33f668  0.526639  0.473361\n",
       "02fa521e1838  0.526639  0.473361\n",
       "040e15f562a2  0.526639  0.473361\n",
       "046e85c7cc7f  0.526639  0.473361"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame(\n",
    "    {\n",
    "        \"Id\": test_ids,\n",
    "        \"class_0\": 1 - y_test_rescaled,\n",
    "        \"class_1\": y_test_rescaled,\n",
    "    }\n",
    ").set_index(\"Id\")\n",
    "\n",
    "submission.to_csv(\"submission.csv\")\n",
    "submission.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLAYGROUND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problematic_ids = [\"2901ef1394b9\", \"cf5439add02c\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[problematic_ids].style.set_table_styles(DF_STYLE).format(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_0_class_train = train.query(\"Class == 0\").drop(\"Class\", axis=1)\n",
    "only_1_class_train = train.query(\"Class == 1\").drop(\"Class\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import percentileofscore\n",
    "\n",
    "for feature in most_important_features:\n",
    "    score = percentileofscore(\n",
    "        only_1_class_train[feature],\n",
    "        train.loc[\"cf5439add02c\", feature],\n",
    "        nan_policy=\"omit\",\n",
    "        kind=\"weak\",\n",
    "    )\n",
    "    print(feature, f\"{score:.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "\n",
    "def outlier_detector(data, method=\"isolation_forest\", **kwargs):\n",
    "    if method == \"isolation_forest\":\n",
    "        detector = IsolationForest(**kwargs)\n",
    "    if method == \"lof\":\n",
    "        detector = LocalOutlierFactor(**kwargs)\n",
    "\n",
    "    data_notna = data[~data.isna().any(axis=1)]\n",
    "    result = detector.fit_predict(data_notna.to_numpy())\n",
    "    outlier_ids = pd.Series(result == -1, index=data_notna.index)\n",
    "    # data_ids = pd.Series(np.zeros_like(data.index), index=data.index, dtype=bool)\n",
    "\n",
    "    return outlier_ids[outlier_ids == True].index.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_detector(X_semi_final, method=\"lof\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
