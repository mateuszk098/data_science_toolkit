{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "code {\n",
       "    background: rgba(42, 53, 125, 0.10) !important;\n",
       "    border-radius: 4px !important;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %load ../general_settings.py\n",
    "import os\n",
    "import shutil\n",
    "import warnings\n",
    "import subprocess\n",
    "from time import strftime\n",
    "from collections import defaultdict\n",
    "from collections import namedtuple\n",
    "from copy import copy\n",
    "from functools import partial\n",
    "from itertools import product\n",
    "from itertools import combinations\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.subplots import make_subplots\n",
    "from colorama import Fore\n",
    "from colorama import Style\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "import joblib\n",
    "import optuna\n",
    "\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy.stats import probplot\n",
    "from scipy.stats import yeojohnson\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Binarizer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "ON_KAGGLE = os.getenv(\"KAGGLE_KERNEL_RUN_TYPE\") is not None\n",
    "\n",
    "# Colorama settings.\n",
    "CLR = (Style.BRIGHT + Fore.BLACK) if ON_KAGGLE else (Style.BRIGHT + Fore.WHITE)\n",
    "RED = Style.BRIGHT + Fore.RED\n",
    "BLUE = Style.BRIGHT + Fore.BLUE\n",
    "CYAN = Style.BRIGHT + Fore.CYAN\n",
    "RESET = Style.RESET_ALL\n",
    "\n",
    "FONT_COLOR = \"#545454\"\n",
    "BACKGROUND_COLOR = \"#F6F5F5\"\n",
    "\n",
    "CELL_HOVER = {  # for row hover use <tr> instead of <td>\n",
    "    \"selector\": \"td:hover\",\n",
    "    \"props\": \"background-color: #F6F5F5\",\n",
    "}\n",
    "TEXT_HIGHLIGHT = {\n",
    "    \"selector\": \"td\",\n",
    "    \"props\": \"color: #545454; font-weight: bold\",\n",
    "}\n",
    "INDEX_NAMES = {\n",
    "    \"selector\": \".index_name\",\n",
    "    \"props\": \"font-style: italic; background-color: #005D68; color: #F2F2F0;\",\n",
    "}\n",
    "HEADERS = {\n",
    "    \"selector\": \"th:not(.index_name)\",\n",
    "    \"props\": \"font-style: italic; background-color: #005D68; color: #F2F2F0;\",\n",
    "}\n",
    "DF_STYLE = (INDEX_NAMES, HEADERS, TEXT_HIGHLIGHT)\n",
    "\n",
    "# Utility functions.\n",
    "def download_dataset_from_kaggle(user, dataset, directory):\n",
    "    command = \"kaggle datasets download -d \"\n",
    "    filepath = directory / (dataset + \".zip\")\n",
    "    if not filepath.is_file():\n",
    "        subprocess.run((command + user + \"/\" + dataset).split())\n",
    "        filepath.parent.mkdir(parents=True, exist_ok=True)\n",
    "        shutil.unpack_archive(dataset + \".zip\", \"data\")\n",
    "        shutil.move(dataset + \".zip\", \"data\")\n",
    "\n",
    "\n",
    "def download_competition_from_kaggle(competition):\n",
    "    command = \"kaggle competitions download -c \"\n",
    "    filepath = Path(\"data/\" + competition + \".zip\")\n",
    "    if not filepath.is_file():\n",
    "        subprocess.run((command + competition).split())\n",
    "        Path(\"data\").mkdir(parents=True, exist_ok=True)\n",
    "        shutil.unpack_archive(competition + \".zip\", \"data\")\n",
    "        shutil.move(competition + \".zip\", \"data\")\n",
    "\n",
    "\n",
    "# Html `code` block highlight. Must be included at the end of all imports!\n",
    "HTML(\n",
    "    \"\"\"\n",
    "<style>\n",
    "code {\n",
    "    background: rgba(42, 53, 125, 0.10) !important;\n",
    "    border-radius: 4px !important;\n",
    "}\n",
    "</style>\n",
    "\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "competition = \"playground-series-s3e18\"\n",
    "\n",
    "if not ON_KAGGLE:\n",
    "    download_competition_from_kaggle(competition)\n",
    "    train_path = \"data/train.csv\"\n",
    "    test_path = \"data/test.csv\"\n",
    "else:\n",
    "    train_path = f\"/kaggle/input/{competition}/train.csv\"\n",
    "    test_path = f\"/kaggle/input/{competition}/test.csv\"\n",
    "\n",
    "cols_to_skip = [\"EC3\", \"EC4\", \"EC5\", \"EC6\"]\n",
    "train = pd.read_csv(train_path, index_col=\"id\", usecols=lambda x: x not in cols_to_skip)\n",
    "test = pd.read_csv(test_path, index_col=\"id\")\n",
    "\n",
    "orig = pd.read_csv(\"data/mixed_desc.csv\")\n",
    "orig[\"EC1_EC2_EC3_EC4_EC5_EC6\".split(\"_\")] = (\n",
    "    orig[\"EC1_EC2_EC3_EC4_EC5_EC6\"].str.split(\"_\", expand=True).astype(np.int32)\n",
    ")\n",
    "orig = orig[train.columns]\n",
    "\n",
    "continuous_variables = test.select_dtypes(\"float64\").columns\n",
    "discrete_variables = test.select_dtypes(\"int64\").columns\n",
    "targets = [\"EC1\", \"EC2\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BertzCT</th>\n",
       "      <th>Chi1</th>\n",
       "      <th>Chi1n</th>\n",
       "      <th>Chi1v</th>\n",
       "      <th>Chi2n</th>\n",
       "      <th>Chi2v</th>\n",
       "      <th>Chi3v</th>\n",
       "      <th>Chi4n</th>\n",
       "      <th>EState_VSA1</th>\n",
       "      <th>EState_VSA2</th>\n",
       "      <th>...</th>\n",
       "      <th>PEOE_VSA7</th>\n",
       "      <th>PEOE_VSA8</th>\n",
       "      <th>SMR_VSA10</th>\n",
       "      <th>SMR_VSA5</th>\n",
       "      <th>SlogP_VSA3</th>\n",
       "      <th>VSA_EState9</th>\n",
       "      <th>fr_COO</th>\n",
       "      <th>fr_COO2</th>\n",
       "      <th>EC1</th>\n",
       "      <th>EC2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4076</th>\n",
       "      <td>633.324985</td>\n",
       "      <td>11.612591</td>\n",
       "      <td>7.945187</td>\n",
       "      <td>7.945187</td>\n",
       "      <td>5.788793</td>\n",
       "      <td>5.788793</td>\n",
       "      <td>3.978973</td>\n",
       "      <td>2.515318</td>\n",
       "      <td>38.969379</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>19.386400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.822697</td>\n",
       "      <td>24.415866</td>\n",
       "      <td>13.825658</td>\n",
       "      <td>54.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6411</th>\n",
       "      <td>378.018438</td>\n",
       "      <td>8.417121</td>\n",
       "      <td>4.473678</td>\n",
       "      <td>5.081423</td>\n",
       "      <td>3.402408</td>\n",
       "      <td>4.402408</td>\n",
       "      <td>2.488006</td>\n",
       "      <td>1.770579</td>\n",
       "      <td>36.992053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.969305</td>\n",
       "      <td>36.809859</td>\n",
       "      <td>4.794537</td>\n",
       "      <td>51.833333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12744</th>\n",
       "      <td>150.255712</td>\n",
       "      <td>5.092224</td>\n",
       "      <td>3.392018</td>\n",
       "      <td>3.392018</td>\n",
       "      <td>2.634453</td>\n",
       "      <td>2.634453</td>\n",
       "      <td>1.890522</td>\n",
       "      <td>1.289775</td>\n",
       "      <td>35.898777</td>\n",
       "      <td>11.250838</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.076020</td>\n",
       "      <td>13.792002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.825658</td>\n",
       "      <td>41.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10285</th>\n",
       "      <td>602.980459</td>\n",
       "      <td>9.719545</td>\n",
       "      <td>6.451852</td>\n",
       "      <td>6.451852</td>\n",
       "      <td>4.797545</td>\n",
       "      <td>4.797545</td>\n",
       "      <td>3.857360</td>\n",
       "      <td>2.135281</td>\n",
       "      <td>29.929472</td>\n",
       "      <td>6.420822</td>\n",
       "      <td>...</td>\n",
       "      <td>6.420822</td>\n",
       "      <td>12.132734</td>\n",
       "      <td>11.876485</td>\n",
       "      <td>36.809859</td>\n",
       "      <td>14.325937</td>\n",
       "      <td>54.833333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4786</th>\n",
       "      <td>231.985252</td>\n",
       "      <td>5.698377</td>\n",
       "      <td>2.934030</td>\n",
       "      <td>2.934030</td>\n",
       "      <td>2.043527</td>\n",
       "      <td>2.043527</td>\n",
       "      <td>1.313518</td>\n",
       "      <td>0.620060</td>\n",
       "      <td>12.011146</td>\n",
       "      <td>12.462662</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.969305</td>\n",
       "      <td>25.304306</td>\n",
       "      <td>4.794537</td>\n",
       "      <td>32.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>522.541944</td>\n",
       "      <td>13.288313</td>\n",
       "      <td>8.487080</td>\n",
       "      <td>8.487080</td>\n",
       "      <td>5.297097</td>\n",
       "      <td>5.297097</td>\n",
       "      <td>3.241954</td>\n",
       "      <td>2.086839</td>\n",
       "      <td>23.887631</td>\n",
       "      <td>18.628754</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.468494</td>\n",
       "      <td>17.845790</td>\n",
       "      <td>6.041841</td>\n",
       "      <td>19.062800</td>\n",
       "      <td>50.166667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13424</th>\n",
       "      <td>276.306871</td>\n",
       "      <td>5.036581</td>\n",
       "      <td>3.414884</td>\n",
       "      <td>3.414884</td>\n",
       "      <td>2.272429</td>\n",
       "      <td>2.272429</td>\n",
       "      <td>1.474040</td>\n",
       "      <td>0.895230</td>\n",
       "      <td>5.969305</td>\n",
       "      <td>11.312963</td>\n",
       "      <td>...</td>\n",
       "      <td>12.132734</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.656692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.166667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5391</th>\n",
       "      <td>430.682001</td>\n",
       "      <td>7.194306</td>\n",
       "      <td>4.173829</td>\n",
       "      <td>4.173829</td>\n",
       "      <td>3.117951</td>\n",
       "      <td>3.117951</td>\n",
       "      <td>2.219537</td>\n",
       "      <td>1.186201</td>\n",
       "      <td>11.570356</td>\n",
       "      <td>5.749512</td>\n",
       "      <td>...</td>\n",
       "      <td>24.117007</td>\n",
       "      <td>23.520590</td>\n",
       "      <td>16.872230</td>\n",
       "      <td>6.420822</td>\n",
       "      <td>16.009896</td>\n",
       "      <td>33.287361</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>126.490225</td>\n",
       "      <td>4.715214</td>\n",
       "      <td>3.281314</td>\n",
       "      <td>3.281314</td>\n",
       "      <td>2.438992</td>\n",
       "      <td>2.438992</td>\n",
       "      <td>1.634858</td>\n",
       "      <td>0.533757</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.907180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.410095</td>\n",
       "      <td>25.304306</td>\n",
       "      <td>4.794537</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7274</th>\n",
       "      <td>399.782009</td>\n",
       "      <td>7.417570</td>\n",
       "      <td>5.147066</td>\n",
       "      <td>5.147066</td>\n",
       "      <td>3.446827</td>\n",
       "      <td>3.446827</td>\n",
       "      <td>2.937764</td>\n",
       "      <td>1.828511</td>\n",
       "      <td>43.157828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.822697</td>\n",
       "      <td>30.705892</td>\n",
       "      <td>9.088795</td>\n",
       "      <td>43.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15761 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          BertzCT       Chi1     Chi1n     Chi1v     Chi2n     Chi2v  \\\n",
       "4076   633.324985  11.612591  7.945187  7.945187  5.788793  5.788793   \n",
       "6411   378.018438   8.417121  4.473678  5.081423  3.402408  4.402408   \n",
       "12744  150.255712   5.092224  3.392018  3.392018  2.634453  2.634453   \n",
       "10285  602.980459   9.719545  6.451852  6.451852  4.797545  4.797545   \n",
       "4786   231.985252   5.698377  2.934030  2.934030  2.043527  2.043527   \n",
       "...           ...        ...       ...       ...       ...       ...   \n",
       "5192   522.541944  13.288313  8.487080  8.487080  5.297097  5.297097   \n",
       "13424  276.306871   5.036581  3.414884  3.414884  2.272429  2.272429   \n",
       "5391   430.682001   7.194306  4.173829  4.173829  3.117951  3.117951   \n",
       "860    126.490225   4.715214  3.281314  3.281314  2.438992  2.438992   \n",
       "7274   399.782009   7.417570  5.147066  5.147066  3.446827  3.446827   \n",
       "\n",
       "          Chi3v     Chi4n  EState_VSA1  EState_VSA2  ...  PEOE_VSA7  \\\n",
       "4076   3.978973  2.515318    38.969379     0.000000  ...  19.386400   \n",
       "6411   2.488006  1.770579    36.992053     0.000000  ...   0.000000   \n",
       "12744  1.890522  1.289775    35.898777    11.250838  ...   0.000000   \n",
       "10285  3.857360  2.135281    29.929472     6.420822  ...   6.420822   \n",
       "4786   1.313518  0.620060    12.011146    12.462662  ...   0.000000   \n",
       "...         ...       ...          ...          ...  ...        ...   \n",
       "5192   3.241954  2.086839    23.887631    18.628754  ...   0.000000   \n",
       "13424  1.474040  0.895230     5.969305    11.312963  ...  12.132734   \n",
       "5391   2.219537  1.186201    11.570356     5.749512  ...  24.117007   \n",
       "860    1.634858  0.533757     0.000000     5.907180  ...   0.000000   \n",
       "7274   2.937764  1.828511    43.157828     0.000000  ...   0.000000   \n",
       "\n",
       "       PEOE_VSA8  SMR_VSA10   SMR_VSA5  SlogP_VSA3  VSA_EState9  fr_COO  \\\n",
       "4076    0.000000   7.822697  24.415866   13.825658    54.250000       0   \n",
       "6411    0.000000   5.969305  36.809859    4.794537    51.833333       1   \n",
       "12744   6.076020  13.792002   0.000000   13.825658    41.666667       1   \n",
       "10285  12.132734  11.876485  36.809859   14.325937    54.833333       1   \n",
       "4786    0.000000   5.969305  25.304306    4.794537    32.666667       1   \n",
       "...          ...        ...        ...         ...          ...     ...   \n",
       "5192   13.468494  17.845790   6.041841   19.062800    50.166667       1   \n",
       "13424   0.000000  11.656692   0.000000    0.000000    39.166667       1   \n",
       "5391   23.520590  16.872230   6.420822   16.009896    33.287361       0   \n",
       "860     0.000000   6.410095  25.304306    4.794537    30.000000       0   \n",
       "7274    0.000000   7.822697  30.705892    9.088795    43.166667       0   \n",
       "\n",
       "       fr_COO2  EC1  EC2  \n",
       "4076         0    0    1  \n",
       "6411         1    1    0  \n",
       "12744        1    0    1  \n",
       "10285        1    1    0  \n",
       "4786         1    0    1  \n",
       "...        ...  ...  ...  \n",
       "5192         1    0    1  \n",
       "13424        1    1    1  \n",
       "5391         0    1    1  \n",
       "860          0    0    1  \n",
       "7274         0    0    1  \n",
       "\n",
       "[15761 rows x 33 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.concat([train, orig], ignore_index=True)\n",
    "\n",
    "outlier_mask_train = (\n",
    "    (train.FpDensityMorgan1 >= test.FpDensityMorgan1.min())\n",
    "    & (train.FpDensityMorgan2 >= test.FpDensityMorgan2.min())\n",
    "    & (train.FpDensityMorgan3 >= test.FpDensityMorgan3.min())\n",
    ")\n",
    "\n",
    "train = train[outlier_mask_train]\n",
    "train = train.drop_duplicates(subset=np.r_[continuous_variables, discrete_variables])\n",
    "train = train.sample(len(train), random_state=42)\n",
    "train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_descr = (\n",
    "    train[continuous_variables]\n",
    "    .describe(percentiles=[0.01, 0.05, 0.25, 0.50, 0.75, 0.95, 0.99])\n",
    "    .drop(\"count\")\n",
    "    .T.rename(columns=str.title)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_scores = defaultdict(tuple)\n",
    "\n",
    "for feature in continuous_variables:\n",
    "    orig = train[feature].dropna()\n",
    "    _, (*_, R_orig) = probplot(orig, rvalue=True)\n",
    "    _, (*_, R_yeojohn) = probplot(yeojohnson(orig)[0], rvalue=True)\n",
    "\n",
    "    if orig.min() >= 0:\n",
    "        _, (*_, R_log) = probplot(np.log1p(orig), rvalue=True)\n",
    "        _, (*_, R_sqrt) = probplot(np.sqrt(orig), rvalue=True)\n",
    "    else:\n",
    "        R_log, R_sqrt = np.nan, np.nan\n",
    "\n",
    "    r2_scores[feature] = (\n",
    "        R_orig * R_orig,\n",
    "        R_yeojohn * R_yeojohn,\n",
    "        R_log * R_log,\n",
    "        R_sqrt * R_sqrt,\n",
    "    )\n",
    "\n",
    "r2_scores_frame = pd.DataFrame(r2_scores, index=(\"Original\", \"YeoJohnson\", \"Log\", \"Sqrt\")).T\n",
    "\n",
    "r2_scores_frame = (\n",
    "    r2_scores_frame.assign(\n",
    "        Winner=r2_scores_frame.idxmax(axis=1),\n",
    "        m=r2_scores_frame.mean(axis=1),\n",
    "    )\n",
    "    .sort_values(by=\"m\", ascending=False)\n",
    "    .drop(\"m\", axis=1)\n",
    ")\n",
    "\n",
    "yeojohnson_transform_cols = r2_scores_frame.query(\"Winner == 'YeoJohnson'\").index\n",
    "log_transform_cols = r2_scores_frame.query(\"Winner == 'Log'\").index\n",
    "sqrt_transform_cols = r2_scores_frame.query(\"Winner == 'Sqrt'\").index\n",
    "\n",
    "semi_constant_mask = np.isclose(numeric_descr[\"Min\"], numeric_descr[\"50%\"])\n",
    "semi_constant_descr = numeric_descr[semi_constant_mask]\n",
    "semi_constant_descr.style.set_table_styles(DF_STYLE).format(precision=3)\n",
    "semi_const_cols_thresholds = semi_constant_descr[\"50%\"].to_dict()\n",
    "\n",
    "semi_const_cols = semi_const_cols_thresholds.keys()\n",
    "yeojohnson_transform_cols = yeojohnson_transform_cols.drop(semi_const_cols, errors=\"ignore\")\n",
    "log_transform_cols = log_transform_cols.drop(semi_const_cols, errors=\"ignore\")\n",
    "sqrt_transform_cols = sqrt_transform_cols.drop(semi_const_cols, errors=\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "preliminary_preprocess = make_column_transformer(\n",
    "    (\n",
    "        make_pipeline(\n",
    "            FunctionTransformer(func=np.log1p, feature_names_out=\"one-to-one\"),\n",
    "            StandardScaler(),\n",
    "        ),\n",
    "        log_transform_cols.to_list(),\n",
    "    ),\n",
    "    (\n",
    "        make_pipeline(\n",
    "            FunctionTransformer(func=np.sqrt, feature_names_out=\"one-to-one\"),\n",
    "            StandardScaler(),\n",
    "        ),\n",
    "        sqrt_transform_cols.to_list(),\n",
    "    ),\n",
    "    (\n",
    "        PowerTransformer(method=\"yeo-johnson\", standardize=True),\n",
    "        yeojohnson_transform_cols.to_list(),\n",
    "    ),\n",
    "    (\n",
    "        MinMaxScaler(),\n",
    "        discrete_variables.to_list(),\n",
    "    ),\n",
    "    *[\n",
    "        (\n",
    "            Binarizer(threshold=thresh),\n",
    "            [col],\n",
    "        )\n",
    "        for col, thresh in semi_const_cols_thresholds.items()\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    verbose_feature_names_out=False,\n",
    ").set_output(transform=\"pandas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_preprocess = make_column_transformer(\n",
    "    (\n",
    "        PCA(n_components=0.95, random_state=42),\n",
    "        [\n",
    "            \"BertzCT\",\n",
    "            \"ExactMolWt\",\n",
    "            \"HeavyAtomMolWt\",\n",
    "            \"Chi1\",\n",
    "            \"Chi1n\",\n",
    "            \"Chi1v\",\n",
    "            \"Chi2n\",\n",
    "            \"Chi2v\",\n",
    "            \"Chi3v\",\n",
    "            \"Chi4n\",\n",
    "        ],\n",
    "    ),\n",
    "    remainder=\"passthrough\",\n",
    "    verbose_feature_names_out=False,\n",
    ").set_output(transform=\"pandas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logging_callback(study, frozen_trial):\n",
    "    previous_best_value = study.user_attrs.get(\"previous_best_value\", None)\n",
    "    if previous_best_value != study.best_value:\n",
    "        study.set_user_attr(\"previous_best_value\", study.best_value)\n",
    "        params = {key.split(\"__\")[-1]: value for key, value in frozen_trial.params.items()}\n",
    "        print(\n",
    "            f\"{CLR}Optuna Trial: {RED}{frozen_trial.number:03} {CLR}- \",\n",
    "            f\"{CLR}Best Value: {RED}{frozen_trial.value:.5f}\\n\",\n",
    "            f\"{CLR}Best Params: {RED}{params}\",\n",
    "            sep=\"\",\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(trial, seed=None):\n",
    "    selector_params = {\n",
    "        \"k\": trial.suggest_int(\"selectkbest__k\", 8, 18, step=2),\n",
    "    }\n",
    "\n",
    "    clf_params = {\n",
    "        \"random_state\": trial.suggest_categorical(\n",
    "            \"gradientboostingclassifier__random_state\", [seed or 42]\n",
    "        ),\n",
    "        \"max_features\": trial.suggest_categorical(\n",
    "            \"gradientboostingclassifier__max_features\", [\"sqrt\"]\n",
    "        ),\n",
    "        \"n_iter_no_change\": trial.suggest_categorical(\n",
    "            \"gradientboostingclassifier__n_iter_no_change\", [20]\n",
    "        ),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\n",
    "            \"gradientboostingclassifier__min_samples_leaf\", 32, 192, step=8\n",
    "        ),\n",
    "        \"n_estimators\": trial.suggest_int(\n",
    "            \"gradientboostingclassifier__n_estimators\", 200, 500, step=100\n",
    "        ),\n",
    "        \"learning_rate\": trial.suggest_float(\n",
    "            \"gradientboostingclassifier__learning_rate\", 1e-2, 2e-1\n",
    "        ),\n",
    "        \"max_depth\": trial.suggest_int(\"gradientboostingclassifier__max_depth\", 3, 5, step=1),\n",
    "        \"subsample\": trial.suggest_float(\n",
    "            \"gradientboostingclassifier__subsample\", 0.5, 0.9, step=0.1\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    return make_pipeline(\n",
    "        preliminary_preprocess,\n",
    "        pca_preprocess,\n",
    "        SelectKBest(**selector_params),\n",
    "        GradientBoostingClassifier(**clf_params),\n",
    "    )\n",
    "\n",
    "\n",
    "def objective(trial, X, y, seed=None):\n",
    "    seed = seed or 42\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    y_oof_proba = np.zeros_like(y, dtype=np.float32)\n",
    "    model = define_model(trial, seed)\n",
    "\n",
    "    for train_ids, valid_ids in skf.split(X, y):\n",
    "        X_train, y_train = X.iloc[train_ids], y.iloc[train_ids]\n",
    "        X_valid, y_valid = X.iloc[valid_ids], y.iloc[valid_ids]\n",
    "        model.fit(X_train, y_train)\n",
    "        y_oof_proba[valid_ids] = model.predict_proba(X_valid)[:, 1]\n",
    "        # Pruning should be here if needed?\n",
    "\n",
    "    return roc_auc_score(y, y_oof_proba)\n",
    "\n",
    "\n",
    "def seed_study(seed, X, y, n_trials=100, n_jobs=-1):\n",
    "    sampler = optuna.samplers.TPESampler(seed=seed)\n",
    "    pruner = optuna.pruners.HyperbandPruner()  # Not used.\n",
    "    study = optuna.create_study(direction=\"maximize\", sampler=sampler, pruner=pruner)\n",
    "    study.optimize(\n",
    "        partial(objective, X=X, y=y, seed=seed),  # type: ignore\n",
    "        n_trials=n_trials,\n",
    "        callbacks=[logging_callback],\n",
    "        n_jobs=n_jobs,\n",
    "    )\n",
    "\n",
    "    best_model = make_pipeline(\n",
    "        preliminary_preprocess, pca_preprocess, SelectKBest(), GradientBoostingClassifier()\n",
    "    ).set_params(**study.best_params)\n",
    "\n",
    "    best_value = np.round(study.best_value, 5)\n",
    "\n",
    "    study_frame = study.trials_dataframe(\n",
    "        attrs=(\"number\", \"value\", \"params\", \"state\"),\n",
    "    ).sort_values(by=\"value\")\n",
    "\n",
    "    return best_model, best_value, study_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "models_ec1_path = Path(f\"models/ec1/\")\n",
    "models_ec2_path = Path(f\"models/ec2/\")\n",
    "models_ec1_path.mkdir(parents=True, exist_ok=True)\n",
    "models_ec2_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "n_seeds = 5\n",
    "seeds = np.random.randint(0, 100, size=n_seeds).tolist()\n",
    "\n",
    "X = train.drop(targets, axis=1)\n",
    "y_ec1 = train.EC1\n",
    "y_ec2 = train.EC2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "\n",
    "\n",
    "def search_for_best_model(X, y, seeds, models_path, n_trials=100, n_jobs=-1):\n",
    "    model_study = namedtuple(\"Study\", [\"best_model\", \"best_value\", \"study_frame\"])\n",
    "    models = defaultdict(model_study)\n",
    "\n",
    "    for seed in seeds:\n",
    "        print(CLR + \"Seed:\", seed)\n",
    "        best_model, best_value, study_frame = seed_study(\n",
    "            seed, X, y, n_trials=n_trials, n_jobs=n_jobs\n",
    "        )\n",
    "        models[seed] = model_study(best_model, best_value, study_frame)\n",
    "        joblib.dump(\n",
    "            best_model,\n",
    "            models_path\n",
    "            / f\"best_gb_seed_{seed:03}_{strftime('run_%Y_%m_%d_%H_%M_%S')}_value_{best_value:.5f}.pkl\",\n",
    "        )\n",
    "        print()\n",
    "\n",
    "    return models\n",
    "\n",
    "\n",
    "print(CLR + \"● EC1 Optimization:\\n\")\n",
    "models_ec1 = search_for_best_model(X, y_ec1, seeds, models_ec1_path)\n",
    "\n",
    "print(CLR + \"● EC2 Optimization:\\n\")\n",
    "models_ec2 = search_for_best_model(X, y_ec2, seeds, models_ec2_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "models_ec1_paths = glob.glob(str(models_ec1_path / \"*\"))\n",
    "models_ec2_paths = glob.glob(str(models_ec2_path / \"*\"))\n",
    "\n",
    "loaded_models_ec1 = defaultdict(object)\n",
    "loaded_models_ec2 = defaultdict(object)\n",
    "\n",
    "for fname in models_ec1_paths:\n",
    "    loaded_models_ec1[fname] = joblib.load(fname)\n",
    "\n",
    "for fname in models_ec2_paths:\n",
    "    loaded_models_ec2[fname] = joblib.load(fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_predict_proba(X, y, models, X_test):\n",
    "    y_test = np.zeros_like(X_test.index, dtype=np.float32)\n",
    "\n",
    "    for seed, best_model in models.items():\n",
    "        best_model.fit(X, y)\n",
    "        y_test += best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    return y_test / len(models)\n",
    "\n",
    "\n",
    "y_test_ec1 = fit_and_predict_proba(X, y_ec1, loaded_models_ec1, test)\n",
    "y_test_ec2 = fit_and_predict_proba(X, y_ec2, loaded_models_ec2, test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_890b9 .index_name {\n",
       "  font-style: italic;\n",
       "  background-color: #005D68;\n",
       "  color: #F2F2F0;\n",
       "}\n",
       "#T_890b9 th:not(.index_name) {\n",
       "  font-style: italic;\n",
       "  background-color: #005D68;\n",
       "  color: #F2F2F0;\n",
       "}\n",
       "#T_890b9 td {\n",
       "  color: #545454;\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_890b9\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_890b9_level0_col0\" class=\"col_heading level0 col0\" >EC1</th>\n",
       "      <th id=\"T_890b9_level0_col1\" class=\"col_heading level0 col1\" >EC2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Id</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_890b9_level0_row0\" class=\"row_heading level0 row0\" >14838</th>\n",
       "      <td id=\"T_890b9_row0_col0\" class=\"data row0 col0\" >0.416994</td>\n",
       "      <td id=\"T_890b9_row0_col1\" class=\"data row0 col1\" >0.760645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_890b9_level0_row1\" class=\"row_heading level0 row1\" >14839</th>\n",
       "      <td id=\"T_890b9_row1_col0\" class=\"data row1 col0\" >0.846555</td>\n",
       "      <td id=\"T_890b9_row1_col1\" class=\"data row1 col1\" >0.829053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_890b9_level0_row2\" class=\"row_heading level0 row2\" >14840</th>\n",
       "      <td id=\"T_890b9_row2_col0\" class=\"data row2 col0\" >0.777841</td>\n",
       "      <td id=\"T_890b9_row2_col1\" class=\"data row2 col1\" >0.748106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_890b9_level0_row3\" class=\"row_heading level0 row3\" >14841</th>\n",
       "      <td id=\"T_890b9_row3_col0\" class=\"data row3 col0\" >0.720877</td>\n",
       "      <td id=\"T_890b9_row3_col1\" class=\"data row3 col1\" >0.798277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_890b9_level0_row4\" class=\"row_heading level0 row4\" >14842</th>\n",
       "      <td id=\"T_890b9_row4_col0\" class=\"data row4 col0\" >0.799203</td>\n",
       "      <td id=\"T_890b9_row4_col1\" class=\"data row4 col1\" >0.815376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1a1cabb9ff0>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame(\n",
    "    {\n",
    "        \"Id\": test.index,\n",
    "        \"EC1\": y_test_ec1,\n",
    "        \"EC2\": y_test_ec2,\n",
    "    }\n",
    ").set_index(\"Id\")\n",
    "\n",
    "submission.to_csv(\"submission.csv\")\n",
    "submission.head().style.set_table_styles(DF_STYLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7044966372452267, 0.5850340006620565)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.calibration import LinearSVC\n",
    "from sklearn.ensemble import (\n",
    "    BaggingClassifier,\n",
    "    ExtraTreesClassifier,\n",
    "    HistGradientBoostingClassifier,\n",
    "    GradientBoostingClassifier,\n",
    ")\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "model = make_pipeline(\n",
    "    preliminary_preprocess,\n",
    "    pca_preprocess,\n",
    "    SelectKBest(k=16),\n",
    "    # LGBMClassifier(random_state=42, max_depth=5, min_child_samples=64, colsample_bytree=0.2),\n",
    "    # Nystroem(gamma=1e-2),\n",
    "    # RandomForestClassifier(random_state=42, min_samples_leaf=64)\n",
    "    Nystroem(),\n",
    "    LinearSVC(C=2.1)\n",
    "    # LogisticRegression(penalty=\"elasticnet\", solver=\"saga\", l1_ratio=0.5, C=2.1)\n",
    "    # KNeighborsClassifier(1000, weights=\"distance\")\n",
    "    # GradientBoostingClassifier(\n",
    "    #     min_samples_leaf=128,\n",
    "    #     max_features=\"sqrt\",\n",
    "    #     n_estimators=500,\n",
    "    #     n_iter_no_change=20,\n",
    "    #     learning_rate=0.02,\n",
    "    #     max_depth=5,\n",
    "    #     random_state=42,\n",
    "    #     subsample=0.5\n",
    "    # )\n",
    "    # XGBClassifier(max_depth=1),\n",
    ")\n",
    "\n",
    "scores_ec1 = cross_val_score(\n",
    "    model,\n",
    "    X,\n",
    "    y_ec1,\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    scoring=\"roc_auc\",\n",
    ")\n",
    "\n",
    "scores_ec2 = cross_val_score(\n",
    "    model,\n",
    "    X,\n",
    "    y_ec2,\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    scoring=\"roc_auc\",\n",
    ")\n",
    "\n",
    "scores_ec1.mean(), scores_ec2.mean()\n",
    "# (0.7069189117588829, 0.5906135076245935)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
